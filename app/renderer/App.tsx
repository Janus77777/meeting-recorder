import React, { useRef, useState } from 'react';
import { SimpleNavigation } from './components/SimpleNavigation';
import { initializeAPI, getAPI, updateAPISettings } from './services/api';
import { GeminiAPIClient } from './services/geminiApi';
import { AppSettings, MeetingStatus, STTTranscriptionResponse, STTTranscriptSegment, TranscriptSegment } from '@shared/types';
import { useSettingsStore, useUIStore, useJobsStore, initializeStores, useToastActions } from './services/store';
import PromptsPage from './pages/PromptsPage';
import { SettingsPage } from './pages/SettingsPage';
import GoogleSTTSettingsPage from './pages/GoogleSTTSettingsPage';
import SummaryView from './components/SummaryView';
import ResultHeader from './components/ResultHeader';
import KitResultHeader from './components/kit/ResultHeader';
import ProgressBar from './components/ProgressBar';
import SummaryCard from './components/SummaryCard';
import HighlightsCard from './components/HighlightsCard';
import DecisionsCard from './components/DecisionsCard';
import TodosCard from './components/TodosCard';
import TimelineCard from './components/TimelineCard';
import SummaryCardKit from './components/kit/SummaryCard';
import HighlightsCardKit from './components/kit/HighlightsCard';
import DecisionsCardKit from './components/kit/DecisionsCard';
import TodosCardKit from './components/kit/TodosCard';
import TimelineCardKit from './components/kit/TimelineCard';
import TranscriptToolbarKit from './components/kit/TranscriptToolbar';
import Icon from './components/Icon';
import { VocabularyService } from './services/vocabularyService';
import { mergeMediaStreams, requestMicrophoneStream, requestSystemAudioStream, stopStream } from './utils/audioCapture';
import { validateMediaFile } from './utils/validators';
import { joinPath, normalizePath } from './utils/path';

const PAGE_META: Record<'record' | 'result' | 'prompts' | 'settings' | 'stt', { title: string; subtitle: string }> = {
  record: {
    title: 'æœƒè­°éŒ„éŸ³å·¥ä½œå®¤',
    subtitle: 'å³æ™‚éŒ„éŸ³æˆ–ä¸Šå‚³æª”æ¡ˆï¼Œå•Ÿå‹•æ™ºæ…§è½‰éŒ„æµç¨‹'
  },
  result: {
    title: 'æŸ¥çœ‹çµæœ',
    subtitle: 'æŸ¥çœ‹å®Œæ•´é€å­—ç¨¿èˆ‡ AI æ‘˜è¦ï¼Œå¿«é€Ÿå›é¡§æœƒè­°é‡é»'
  },
  prompts: {
    title: 'æç¤ºè©ç®¡ç†',
    subtitle: 'èª¿æ•´é€å­—ç¨¿èˆ‡æ‘˜è¦æç¤ºè©ï¼Œå®¢åˆ¶åŒ–ä½ æƒ³è¦çš„è¼¸å‡ºæ ¼å¼'
  },
  settings: {
    title: 'ç³»çµ±è¨­å®š',
    subtitle: 'é€£ç·š APIã€èª¿æ•´åå¥½èˆ‡æ¬Šé™è¨­å®š'
  },
  stt: {
    title: 'Google STT è©³ç´°è¨­å®š',
    subtitle: 'é…ç½®å°ˆæ¡ˆã€è¾¨è­˜å™¨ã€æ¨¡å‹èˆ‡èªè¨€ç­‰åƒæ•¸'
  }
};

type ParsedTranscriptLine = {
  speaker?: string;
  text: string;
};

const MAX_CLEANUP_CHARS = 7000;

const JOB_STATUS_HINTS: Record<string, string> = {
  queued: 'ä»»å‹™æ’éšŠä¸­ï¼Œç¨å€™é–‹å§‹è™•ç†',
  stt: 'èªéŸ³è½‰æ–‡å­—é€²è¡Œä¸­',
  summarize: 'æ­£åœ¨ç”Ÿæˆæ‘˜è¦',
  done: 'è½‰éŒ„å®Œæˆï¼Œå¯å‰å¾€çµæœé æŸ¥çœ‹',
  failed: 'è™•ç†å¤±æ•—'
};

const openSystemPreference = async (target: 'microphone' | 'screen') => {
  try {
    const api = (window as any).electronAPI;
    if (api?.permissions?.openSystemPreference) {
      await api.permissions.openSystemPreference(target);
    }
  } catch (error) {
    console.warn('ç„¡æ³•è‡ªå‹•é–‹å•Ÿç³»çµ±åå¥½è¨­å®š:', error);
  }
};

const requestMicrophoneAccess = async () => {
  try {
    const api = (window as any).electronAPI;
    if (api?.permissions?.requestMediaAccess) {
      const granted = await api.permissions.requestMediaAccess('microphone');
      return granted;
    }
  } catch (error) {
    console.warn('ç„¡æ³•è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™:', error);
  }
  return false;
};

const chunkTranscriptForCleanup = (transcript: string, maxChars: number = MAX_CLEANUP_CHARS): string[] => {
  if (!transcript || transcript.trim().length === 0) {
    return [];
  }

  const lines = transcript.split(/\r?\n/);
  const chunks: string[] = [];
  let buffer: string[] = [];
  let currentLength = 0;

  const pushBuffer = () => {
    if (buffer.length) {
      chunks.push(buffer.join('\n'));
      buffer = [];
      currentLength = 0;
    }
  };

  for (const line of lines) {
    const lineLength = line.length + 1; // include newline
    if (currentLength + lineLength > maxChars && buffer.length > 0) {
      pushBuffer();
    }
    buffer.push(line);
    currentLength += lineLength;
  }

  pushBuffer();

  return chunks.length > 0 ? chunks : [transcript];
};

const cleanupTranscriptInChunks = async (
  client: GeminiAPIClient,
  transcript: string,
  cleanupPrompt?: string
): Promise<string> => {
  const chunks = chunkTranscriptForCleanup(transcript);
  if (chunks.length <= 1) {
    return client.cleanupTranscript(transcript, cleanupPrompt);
  }

  const cleanedChunks: string[] = [];

  for (let index = 0; index < chunks.length; index++) {
    const chunk = chunks[index];
    try {
      const cleaned = await client.cleanupTranscript(chunk, cleanupPrompt);
      cleanedChunks.push(cleaned);
    } catch (error) {
      console.warn(`é€å­—ç¨¿åˆ†æ®µä¿®æ­£å¤±æ•—ï¼Œç¬¬ ${index + 1}/${chunks.length} æ®µå°‡ä½¿ç”¨åŸå§‹å…§å®¹`, error);
      cleanedChunks.push(chunk);
    }
  }

  return cleanedChunks.join('\n\n').replace(/\n{3,}/g, '\n\n').trim();
};

const parseTranscriptLines = (transcript: string): ParsedTranscriptLine[] => {
  if (!transcript || !transcript.trim()) {
    return [];
  }

  return transcript
    .split(/\r?\n/)
    .map(line => line.trim())
    .filter(line => {
      if (!line || line.length === 0) return false;
      if (line.startsWith('# Legend')) return false;
      // ç•¥éåƒ…åŒ…å« Speaker æ¨™è¨˜ä¸”æ²’æœ‰å…§å®¹çš„è¡Œ
      if (/^\[?\s*Speaker\s+\d+\s*\]?$/i.test(line)) {
        return false;
      }
      return true;
    })
    .map<ParsedTranscriptLine>(line => {
      const match = line.match(/^\[(.+?)\]:\s*(.*)$/);
      if (match) {
        const rawSpeaker = match[1]?.trim();
        const speaker = rawSpeaker.replace(/\|.*/, '').trim();
        return {
          speaker: speaker.length ? speaker : undefined,
          text: match[2]?.trim() ?? ''
        };
      }
      return { text: line };
    })
    .filter(entry => entry.text.length > 0 || (entry.speaker && entry.speaker.length > 0));
};

const mergeSegmentsWithCleanTranscript = (
  segments: TranscriptSegment[] = [],
  cleanedTranscript: string
): TranscriptSegment[] => {
  const parsedLines = parseTranscriptLines(cleanedTranscript);
  if (!parsedLines.length) {
    return segments;
  }

  const merged: TranscriptSegment[] = [];
  const maxIndex = Math.min(segments.length, parsedLines.length);

  for (let i = 0; i < maxIndex; i++) {
    const segment = segments[i];
    const line = parsedLines[i];
    merged.push({
      // åƒ…è¦†å¯« speaker/textï¼Œä¸å‹•æ™‚é–“æˆ³ï¼Œç¢ºä¿ 1:1 å°é½Š
      start: segment.start,
      end: segment.end,
      speaker: line.speaker ?? segment.speaker,
      text: line.text
    });
  }

  if (parsedLines.length > segments.length) {
    const lastEnd = merged[merged.length - 1]?.end ?? 0;
    for (let i = segments.length; i < parsedLines.length; i++) {
      const line = parsedLines[i];
      merged.push({
        // æ–°å¢çš„è¡Œï¼šä»¥ä¸Šä¸€æ®µ end ä½œç‚º startï¼Œend æš«ç¼ºï¼ˆæ¸²æŸ“æ™‚æœƒé¡¯ç¤º --:--ï¼‰
        start: typeof lastEnd === 'number' ? lastEnd : 0,
        end: undefined as any,
        speaker: line.speaker ?? 'Speaker',
        text: line.text
      });
    }
  } else if (segments.length > parsedLines.length) {
    for (let i = parsedLines.length; i < segments.length; i++) {
      merged.push(segments[i]);
    }
  }

  return merged;
};

const App: React.FC = () => {
  // ä½¿ç”¨UI storeç®¡ç†é é¢ç‹€æ…‹
  const { currentPage, setCurrentPage } = useUIStore();
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [recordingStatus, setRecordingStatus] = useState<string>('æº–å‚™é–‹å§‹éŒ„éŸ³...');
  const [hasAudioPermission, setHasAudioPermission] = useState<boolean | null>(null);
  const [recordingMode, setRecordingMode] = useState<'microphone' | 'system' | 'both'>('both'); // éŒ„éŸ³æ¨¡å¼
  const [systemStream, setSystemStream] = useState<MediaStream | null>(null);
  const [microphoneStream, setMicrophoneStream] = useState<MediaStream | null>(null);
  const [recordings, setRecordings] = useState<Array<{
    id: string;
    filename: string;
    blob: Blob;
    timestamp: string;
    duration: number;
    size: number;
    filePath?: string;
    chunks?: Blob[];
  }>>([]);
  
  // ä½¿ç”¨ Zustand store ç®¡ç†è¨­å®šå’Œä½œæ¥­
  const { settings, updateSettings } = useSettingsStore();
  const { showSuccess, showError } = useToastActions();
  const { jobs, addJob, updateJob, removeJob } = useJobsStore();
  
  // è¿½è¹¤è¨­å®šæ˜¯å¦å·²å¾ localStorage æ¢å¾©
  const [isSettingsHydrated, setIsSettingsHydrated] = useState(false);
  
  // è¿½è¹¤æ­£åœ¨è™•ç†çš„è½‰éŒ„ä»»å‹™ï¼Œé˜²æ­¢é‡è¤‡åŸ·è¡Œ
  const [processingJobs, setProcessingJobs] = useState<Set<string>>(new Set());
  
  // çµæœé é¢çš„åˆ†é ç‹€æ…‹
  const [currentJobIndex, setCurrentJobIndex] = useState(0);
  const [isResultDetailsOpen, setIsResultDetailsOpen] = useState(false);
  const [detailTab, setDetailTab] = useState<'overview' | 'highlights' | 'decisions' | 'todos' | 'timeline' | 'transcript'>('overview');
  const [showTranscript, setShowTranscript] = useState(false);
  // å–®é åˆ†é å‘ˆç¾ï¼Œä¸ä½¿ç”¨å…§éƒ¨éŒ¨é»æ²å‹•
  
  // çµæœé é¢çš„é¡¯ç¤ºæ¨¡å¼ï¼š'summary' | 'transcript'
  const [resultViewMode, setResultViewMode] = useState<'summary' | 'transcript'>('summary');
  // çµæœæ¸…å–®åˆ†é 
  const [resultsPage, setResultsPage] = useState(1);
  const transcriptContainerRef = useRef<HTMLDivElement | null>(null);
  const transcriptItemRefs = useRef<Array<HTMLDivElement | null>>([]);
  const [transcriptQuery, setTranscriptQuery] = useState('');
  const [transcriptSpeaker, setTranscriptSpeaker] = useState('');
  const [showRawSummary, setShowRawSummary] = useState(false);

  const cancelRecordingRef = React.useRef(false);
  const hasResetStaleJobsRef = React.useRef(false);
  // é€²åº¦ä¼°ç®—ï¼ˆçœŸå¯¦ç™¾åˆ†æ¯”ï¼‰ï¼šä»¥ã€Œå·²è™•ç†çš„åª’é«”ç§’æ•¸ / ç¸½åª’é«”ç§’æ•¸ã€ç‚ºä¸»
  const progressEstRef = React.useRef<Record<string, { startTs: number; totalSeconds: number; processedSeconds: number; lastEmitTs: number }>>({});

  // æ›´æ–°ç‹€æ…‹
  const [updateAvailable, setUpdateAvailable] = useState(false);
  const [updateInfo, setUpdateInfo] = useState<{ version: string; releaseNotes?: string } | null>(null);
  const [updateProgress, setUpdateProgress] = useState<{ percent: number; status: string } | null>(null);
  const [updateDownloaded, setUpdateDownloaded] = useState(false);
  const [appVersion, setAppVersion] = useState<string>('');
  const [platform, setPlatform] = useState<NodeJS.Platform | 'unknown'>('unknown');
  const [updateStatusMessage, setUpdateStatusMessage] = useState<string>('å°šæœªæª¢æŸ¥æ›´æ–°');

  type AudioSegment = {
    index: number;
    blob: Blob;
    start: number;
    end: number;
    duration: number;
  };

  const DEFAULT_SEGMENT_MAX_DURATION_SECONDS = 360; // 6 åˆ†é˜ï¼ˆGemini ç›´æ¥æ¨¡å¼ï¼‰
  const DEFAULT_SEGMENT_MIN_DURATION_SECONDS = 90;  // é¿å…æœ€å¾Œä¸€æ®µéçŸ­
  const STT_SEGMENT_MAX_DURATION_SECONDS = 50;      // Google STT é™åˆ¶å»ºè­°ï¼šå–®æ®µå°æ–¼ 1 åˆ†é˜
  const STT_SEGMENT_MIN_DURATION_SECONDS = 10;      // ä¿æŒçµæœå¯ç”¨æ€§ï¼Œé¿å…éçŸ­ç‰‡æ®µ
  const STT_SEGMENT_MAX_BYTES = 7 * 1024 * 1024;    // STT æ®µè½æœ€å¤§å¤§å°ï¼ˆ7MB åŸå§‹è³‡æ–™ï¼‰
  const STT_BASE64_EXPANSION_FACTOR = 4 / 3;        // base64 æ”¾å¤§ä¿‚æ•¸

  interface SegmentOptions {
    maxDurationSeconds?: number;
    minDurationSeconds?: number;
    maxSegmentBytes?: number;
  }

  const normalizeMimeType = (mime?: string): string | undefined => {
    if (!mime) {
      return undefined;
    }
    return mime.split(';')[0]?.trim().toLowerCase();
  };

  const inferExtensionFromMime = (mime?: string): string => {
    const normalized = normalizeMimeType(mime);
    switch (normalized) {
      case 'audio/mpeg':
      case 'audio/mp3':
        return 'mp3';
      case 'audio/mp4':
      case 'audio/x-m4a':
      case 'audio/m4a':
        return 'm4a';
      case 'audio/aac':
        return 'aac';
      case 'audio/ogg':
        return 'ogg';
      case 'audio/opus':
        return 'opus';
      case 'audio/wav':
      case 'audio/x-wav':
      case 'audio/wave':
      case 'audio/vnd.wave':
        return 'wav';
      case 'audio/flac':
        return 'flac';
      case 'audio/webm':
      case 'audio/webm;codecs=opus':
      default:
        return 'webm';
    }
  };

  const inferMimeFromExtension = (filename: string): string | undefined => {
    const ext = filename.split('.').pop()?.toLowerCase();
    switch (ext) {
      case 'mp3':
        return 'audio/mpeg';
      case 'wav':
        return 'audio/wav';
      case 'm4a':
      case 'mp4a':
        return 'audio/m4a';
      case 'aac':
        return 'audio/aac';
      case 'flac':
        return 'audio/flac';
      case 'ogg':
        return 'audio/ogg';
      case 'opus':
        return 'audio/opus';
      case 'webm':
        return 'audio/webm';
      case 'mp4':
        return 'video/mp4';
      case 'mov':
        return 'video/quicktime';
      case 'avi':
        return 'video/avi';
      default:
        return undefined;
    }
  };

  const handleChooseSavePath = async () => {
    try {
      const picked = (window as any).electronAPI?.dialog?.openDirectory ? await (window as any).electronAPI.dialog.openDirectory() : { canceled: true };
      if (picked?.canceled) return;
      const dir = picked.directoryPath as string;
      if (dir && dir.trim()) {
        updateSettings({ recordingSavePath: dir });
        showSuccess?.(`å·²è¨­å®šéŒ„éŸ³å„²å­˜ç›®éŒ„ï¼š${dir}`);
      }
    } catch (e) {
      showError?.(`é¸æ“‡å„²å­˜ç›®éŒ„å¤±æ•—ï¼š${(e as Error).message}`);
    }
  };

  const createAudioSegments = (
    fullBlob: Blob,
    chunkList: Blob[] = [],
    totalDuration: number = recordingTime,
    options: SegmentOptions = {}
  ): AudioSegment[] => {
    const maxBytes = options.maxSegmentBytes ?? Number.POSITIVE_INFINITY;

    const chunkCount = chunkList?.length ?? 0;
    const hasChunks = chunkCount > 0;

    const validDuration = Number.isFinite(totalDuration) && totalDuration > 0
      ? totalDuration
      : undefined;

    const approxChunkDuration = hasChunks && validDuration
      ? validDuration / chunkCount
      : undefined;

    const maxDuration = options.maxDurationSeconds ?? DEFAULT_SEGMENT_MAX_DURATION_SECONDS;
    const minDuration = options.minDurationSeconds ?? DEFAULT_SEGMENT_MIN_DURATION_SECONDS;

    const maxChunksPerSegment = approxChunkDuration
      ? Math.max(1, Math.floor(maxDuration / approxChunkDuration))
      : undefined;

    const segments: AudioSegment[] = [];

    const pushSegment = (segmentBlob: Blob, index: number, startTime: number, endTime: number) => {
      const duration = Math.max(endTime - startTime, approxChunkDuration ?? (validDuration ?? 0));
      segments.push({
        index: segments.length,
        blob: segmentBlob,
        start: startTime,
        end: endTime,
        duration
      });
    };

    const shouldSplitBySize = (blob: Blob): boolean => {
      if (!Number.isFinite(maxBytes)) {
        return false;
      }
      if (blob.size <= maxBytes) {
        return false;
      }
      return blob.size * STT_BASE64_EXPANSION_FACTOR > 10 * 1024 * 1024;
    };

    if (!hasChunks) {
      if (!validDuration) {
        pushSegment(fullBlob, 0, 0, 0);
        return segments;
      }

      const targetBytes = Number.isFinite(maxBytes) && maxBytes > 0 ? maxBytes : fullBlob.size;
      const segmentCountBySize = Math.max(1, Math.ceil(fullBlob.size / targetBytes));
      const segmentCountByDuration = Math.max(1, Math.ceil(validDuration / maxDuration));
      const segmentCount = Math.max(segmentCountBySize, segmentCountByDuration);

      if (segmentCount === 1) {
        pushSegment(fullBlob, 0, 0, validDuration);
        return segments;
      }

      const bytesPerSegment = Math.ceil(fullBlob.size / segmentCount);

      let byteStart = 0;
      for (let segmentIndex = 0; segmentIndex < segmentCount; segmentIndex++) {
        const byteEnd = segmentIndex === segmentCount - 1
          ? fullBlob.size
          : Math.min(fullBlob.size, byteStart + bytesPerSegment);

        const startTime = (validDuration * byteStart) / (fullBlob.size || 1);
        const endTime = segmentIndex === segmentCount - 1
          ? validDuration
          : (validDuration * byteEnd) / (fullBlob.size || 1);

        const segmentBlob = fullBlob.slice(byteStart, byteEnd, fullBlob.type || 'audio/webm');
        pushSegment(segmentBlob, segmentIndex, startTime, endTime);

        byteStart = byteEnd;
      }

      return segments;
    }

    let currentChunks: Blob[] = [];
    let segmentStartIndex = 0;

    const finalizeSegment = (endIndexExclusive: number) => {
      if (currentChunks.length === 0) {
        return;
      }

      const startTime = approxChunkDuration ? segmentStartIndex * approxChunkDuration : (validDuration ?? 0);
      const chunkSpan = approxChunkDuration ? currentChunks.length * approxChunkDuration : (validDuration ?? 0);
      const endTime = validDuration ? Math.min(validDuration, startTime + chunkSpan) : startTime + chunkSpan;

      let segmentBlob = new Blob(currentChunks, { type: fullBlob.type || 'audio/webm' });
      const bytesPerChunk = chunkCount > 0 ? fullBlob.size / chunkCount : fullBlob.size;
      let segmentByteStart = segmentStartIndex * bytesPerChunk;

      if (shouldSplitBySize(segmentBlob)) {
        const splits = Math.ceil(segmentBlob.size / (maxBytes || segmentBlob.size));
        const bytesPerSplit = Math.ceil(segmentBlob.size / splits);

        for (let splitIndex = 0; splitIndex < splits; splitIndex++) {
          const splitByteStart = segmentByteStart + splitIndex * bytesPerSplit;
          const splitByteEnd = splitIndex === splits - 1
            ? segmentByteStart + segmentBlob.size
            : splitByteStart + bytesPerSplit;

          const splitStartTime = validDuration
            ? (validDuration * splitByteStart) / (fullBlob.size || 1)
            : startTime;
          const splitEndTime = validDuration
            ? (validDuration * splitByteEnd) / (fullBlob.size || 1)
            : endTime;

          const splitBlob = segmentBlob.slice(
            splitIndex * bytesPerSplit,
            splitIndex === splits - 1 ? segmentBlob.size : (splitIndex + 1) * bytesPerSplit,
            fullBlob.type || 'audio/webm'
          );
          pushSegment(splitBlob, segments.length, splitStartTime, splitEndTime);
        }
      } else {
        pushSegment(segmentBlob, segments.length, startTime, endTime);
      }

      currentChunks = [];
      segmentStartIndex = endIndexExclusive;
    };

    chunkList.forEach((chunk, idx) => {
      currentChunks.push(chunk);
      const isLastChunk = idx === chunkCount - 1;

      let reachedDurationLimit = false;
      if (maxChunksPerSegment && approxChunkDuration) {
        reachedDurationLimit = currentChunks.length >= maxChunksPerSegment;
      }

      const tempSegment = new Blob(currentChunks, { type: fullBlob.type || 'audio/webm' });
      const reachedSizeLimit = shouldSplitBySize(tempSegment);

      if (reachedDurationLimit || reachedSizeLimit || isLastChunk) {
        finalizeSegment(idx + 1);
      }
    });

    if (segments.length === 0) {
      finalizeSegment(chunkCount);
    }

    if (segments.length > 1 && approxChunkDuration) {
      const lastSegment = segments[segments.length - 1];
      if (lastSegment.duration < minDuration) {
        const prev = segments[segments.length - 2];
        const mergedBlob = new Blob([prev.blob, lastSegment.blob], { type: fullBlob.type || 'audio/webm' });
        const mergedSegment: AudioSegment = {
          index: prev.index,
          blob: mergedBlob,
          start: prev.start,
          end: lastSegment.end,
          duration: lastSegment.end - prev.start
        };
        segments.splice(segments.length - 2, 2, mergedSegment);
      }
    }

    return segments.map((segment, idx) => ({ ...segment, index: idx }));
  };

  const createSTTAudioSegments = (
    fullBlob: Blob,
    chunkList: Blob[] = [],
    totalDuration: number = recordingTime
  ): AudioSegment[] => {
    return createAudioSegments(fullBlob, chunkList, totalDuration, {
      maxDurationSeconds: STT_SEGMENT_MAX_DURATION_SECONDS,
      minDurationSeconds: STT_SEGMENT_MIN_DURATION_SECONDS,
      maxSegmentBytes: STT_SEGMENT_MAX_BYTES
    });
  };

  const formatSecondsToTimestamp = (seconds?: number): string => {
    if (seconds === undefined || seconds === null || Number.isNaN(seconds)) {
      return '00:00';
    }
    const totalSeconds = Math.max(0, Math.floor(seconds));
    const hours = Math.floor(totalSeconds / 3600);
    const minutes = Math.floor((totalSeconds % 3600) / 60);
    const secs = totalSeconds % 60;
    if (hours > 0) {
      return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs
        .toString()
        .padStart(2, '0')}`;
    }
    return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  const formatEta = (seconds: number): string => {
    if (!Number.isFinite(seconds) || seconds < 0) return '--:--';
    const m = Math.floor(seconds / 60);
    const s = Math.floor(seconds % 60);
    return `${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}`;
  };

  const safeUpdateJobProgress = (jobId: string, processed: number, total: number, stageLabel: string) => {
    const now = Date.now();
    const state = progressEstRef.current[jobId] || { startTs: now, totalSeconds: total || 1, processedSeconds: 0, lastEmitTs: 0 };
    state.totalSeconds = Math.max(total || 1, 1);
    state.processedSeconds = Math.min(Math.max(processed, 0), state.totalSeconds);
    progressEstRef.current[jobId] = state;

    const elapsed = Math.max((now - state.startTs) / 1000, 0.001);
    const speed = state.processedSeconds / elapsed; // æ¯ç§’è™•ç†çš„åª’é«”ç§’æ•¸
    const remain = Math.max(state.totalSeconds - state.processedSeconds, 0);
    const eta = speed > 0 ? remain / speed : Infinity;
    const percent = Math.max(0, Math.min(100, Math.round((state.processedSeconds / state.totalSeconds) * 100)));

    // ç¯€æµï¼Œé¿å…ç‹€æ…‹æ¬„è¨Šæ¯å¿«é€Ÿé–ƒå‹•
    if (now - state.lastEmitTs < 800 && percent < 100) return;
    state.lastEmitTs = now;

    const hint = `${stageLabel} Â· ${percent}%ï¼ˆé ä¼°å‰©é¤˜ ${formatEta(eta)}ï¼‰`;
    updateJob(jobId, { progress: percent, progressMessage: hint });
  };

  const buildTranscriptFromSTTSegments = (segments: STTTranscriptSegment[] = []): {
    formattedSegments: TranscriptSegment[];
    text: string;
  } => {
    if (!segments.length) {
      return { formattedSegments: [], text: '' };
    }

    const maxGapSeconds = 2;
    const sorted = [...segments].sort((a, b) => {
      const aStart = a.startTime ?? 0;
      const bStart = b.startTime ?? 0;
      return aStart - bStart;
    });

    type WorkingSegment = {
      speakerTag: number | undefined;
      startTime: number;
      endTime: number;
      words: string[];
    };

    const combined: WorkingSegment[] = [];

    for (const word of sorted) {
      const start = word.startTime ?? word.endTime ?? 0;
      const end = word.endTime ?? word.startTime ?? start;
      const speakerTag = word.speakerTag;

      const last = combined[combined.length - 1];
      const gap = last ? start - last.endTime : Number.POSITIVE_INFINITY;

      if (
        !last ||
        last.speakerTag !== speakerTag ||
        gap > maxGapSeconds
      ) {
        combined.push({
          speakerTag,
          startTime: start,
          endTime: end,
          words: [word.text ?? '']
        });
      } else {
        last.words.push(word.text ?? '');
        last.endTime = end;
      }
    }

    const formattedSegments: TranscriptSegment[] = combined.map(seg => {
      const speakerLabel = seg.speakerTag ? `Speaker ${seg.speakerTag}` : 'Speaker';
      return {
        // ä»¥æ•¸å€¼ç§’æ•¸å„²å­˜ï¼Œç¢ºä¿ä¹‹å¾Œè·³è½‰å°é½Š Google STT æ™‚é–“æˆ³
        start: seg.startTime,
        end: seg.endTime,
        speaker: speakerLabel,
        text: seg.words.join(' ').replace(/\s+/g, ' ').trim()
      };
    });

    const text = formattedSegments
      .map(seg => {
        const range = `${seg.start} - ${seg.end}`;
        return `[${seg.speaker} ${range}]: ${seg.text}`;
      })
      .join('\n');

    return { formattedSegments, text };
  };

  const getGeminiKey = (config: AppSettings): string | undefined => {
    if (config.geminiApiKey && config.geminiApiKey.trim()) {
      return config.geminiApiKey;
    }
    if (config.apiKey && config.apiKey.trim()) {
      return config.apiKey;
    }
    return undefined;
  };

  const getBlobDuration = (blob: Blob): Promise<number> => {
    return new Promise((resolve, reject) => {
      const isVideo = !!blob.type && blob.type.startsWith('video');
      const mediaEl = document.createElement(isVideo ? 'video' : 'audio') as HTMLMediaElement;
      const url = URL.createObjectURL(blob);

      const cleanup = () => {
        URL.revokeObjectURL(url);
        mediaEl.remove();
      };

      let timeoutHandle: ReturnType<typeof setTimeout> | null = setTimeout(() => {
        timeoutHandle = null;
        cleanup();
        reject(new Error('åª’é«”é•·åº¦è®€å–é€¾æ™‚'));
      }, 10000);

      mediaEl.preload = 'metadata';
      if (isVideo) {
        mediaEl.muted = true;
        mediaEl.setAttribute('playsinline', 'true');
      }

      mediaEl.onloadedmetadata = () => {
        if (timeoutHandle) {
          clearTimeout(timeoutHandle);
        }
        const duration = mediaEl.duration;
        cleanup();
        if (!Number.isFinite(duration) || duration <= 0) {
          reject(new Error('ç„¡æ³•å–å¾—åª’é«”é•·åº¦'));
        } else {
          resolve(duration);
        }
      };

      mediaEl.onerror = () => {
        if (timeoutHandle) {
          clearTimeout(timeoutHandle);
        }
        cleanup();
        reject(new Error('åª’é«”è¼‰å…¥å¤±æ•—'));
      };

      mediaEl.src = url;
      mediaEl.load();
    });
  };

  // åˆå§‹åŒ–è¨­å®šå’ŒAPI
  React.useEffect(() => {
    console.log('æ‡‰ç”¨å•Ÿå‹•ï¼Œç•¶å‰è¨­å®š:', settings);
    
    // ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœè¨­å®šå·²ç¶“è¼‰å…¥å®Œæˆï¼ˆæœ‰ baseURLï¼‰ï¼Œå°±æ¨™è¨˜ç‚º hydrated
    if (settings.baseURL && settings.baseURL !== '') {
      console.log('Settings å·²æ¢å¾©ï¼Œç›´æ¥åˆå§‹åŒ–');
      setIsSettingsHydrated(true);
      initializeAPI(settings);
      updateAPISettings(settings);
      console.log('æ‡‰ç”¨åˆå§‹åŒ–å®Œæˆï¼ŒGemini API Key:', getGeminiKey(settings) ? 'å·²è¨­å®š' : 'æœªè¨­å®š');
    } else {
      // å¦‚æœé‚„æ²’æ¢å¾©ï¼Œç­‰å¾…ä¸€ä¸‹å†æª¢æŸ¥
      const timer = setTimeout(() => {
        const currentSettings = useSettingsStore.getState().settings;
        console.log('å»¶é²æª¢æŸ¥è¨­å®š:', currentSettings);
        setIsSettingsHydrated(true);
        initializeAPI(currentSettings);
        updateAPISettings(currentSettings);
        console.log('å»¶é²åˆå§‹åŒ–å®Œæˆï¼ŒGemini API Key:', getGeminiKey(currentSettings) ? 'å·²è¨­å®š' : 'æœªè¨­å®š');
      }, 100);
      
      return () => clearTimeout(timer);
    }
  }, [settings]);

  React.useEffect(() => {
    const detectPlatform = async () => {
      try {
        const result = await window.electronAPI?.app.getPlatform();
        if (result) {
          setPlatform(result as NodeJS.Platform);
          console.log('åµæ¸¬åˆ°ä½œæ¥­ç³»çµ±å¹³å°:', result);
        }
      } catch (error) {
        console.warn('åµæ¸¬ä½œæ¥­ç³»çµ±å¹³å°å¤±æ•—:', error);
      }
    };

    detectPlatform();
  }, []);

  // Timer effect for recording time
  React.useEffect(() => {
    let interval: NodeJS.Timeout;
    if (isRecording) {
      interval = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    }
    return () => clearInterval(interval);
  }, [isRecording]);

  // Check audio permission on load
  React.useEffect(() => {
    checkAudioPermission();
  }, []);

  React.useEffect(() => {
    const completed = jobs.filter(job => job.status === 'done' && (job.summary || job.transcript));
    setCurrentJobIndex(prev => {
      if (completed.length === 0) {
        return 0;
      }
      const clamped = Math.max(0, Math.min(prev, completed.length - 1));
      return clamped;
    });
  }, [jobs]);

  // ä¾æ“šçµæœæ•¸èª¿æ•´åˆ†é ï¼ˆé¿å…åˆªé™¤å¾Œé ç¢¼è¶…å‡ºï¼‰
  React.useEffect(() => {
    const count = jobs.filter(job => job.status === 'done' && (job.summary || job.transcript)).length;
    const pageSize = 12;
    const totalPages = Math.max(1, Math.ceil(count / pageSize));
    setResultsPage(prev => Math.min(prev, totalPages));
  }, [jobs]);

  // ç§»é™¤æ•´é«”ç¸®æ”¾ç­–ç•¥ï¼Œæ”¹ä»¥ CSS æ–·é»å£“ç¸®/éš±è—æ§åˆ¶é«˜åº¦ï¼Œé¿å…è£åˆ‡

  React.useEffect(() => {
    if (hasResetStaleJobsRef.current) {
      return;
    }

    if (processingJobs.size > 0) {
      return;
    }

    if (jobs.length === 0) {
      return;
    }

    const pendingJobs = jobs.filter(job => job.status !== 'done' && job.status !== 'failed');
    if (pendingJobs.length === 0) {
      hasResetStaleJobsRef.current = true;
      return;
    }

    pendingJobs.forEach(job => {
      updateJob(job.id, {
        status: 'failed',
        progress: 0,
        progressMessage: `å…ˆå‰æœªå®Œæˆçš„ä»»å‹™ï¼ˆ${job.filename}ï¼‰å·²åœæ­¢ï¼Œè«‹é‡æ–°å•Ÿå‹•è½‰éŒ„ã€‚`,
        errorMessage: 'æ‡‰ç”¨ç¨‹å¼é‡æ–°å•Ÿå‹•å¾Œï¼Œä¸Šä¸€å€‹ä»»å‹™å·²çµ‚æ­¢ã€‚'
      });
    });

    hasResetStaleJobsRef.current = true;
  }, [jobs, processingJobs, updateJob]);

  // è¨­ç½®æ›´æ–°ç›£è½å™¨
  React.useEffect(() => {
    const api = window.electronAPI;

    if (api?.updater) {
      api.updater.onUpdateAvailable((info) => {
        console.log('ç™¼ç¾æ–°ç‰ˆæœ¬:', info.version);
        setUpdateAvailable(true);
        setUpdateDownloaded(false);
        setUpdateInfo(info);
        setUpdateStatusMessage(`ç™¼ç¾æ–°ç‰ˆæœ¬ ${info.version}`);
        setUpdateProgress(null);
      });

      api.updater.onUpdateProgress((progress) => {
        console.log('æ›´æ–°ä¸‹è¼‰é€²åº¦:', progress.percent + '%');
        setUpdateProgress({
          percent: progress.percent,
          status: `ä¸‹è¼‰ä¸­... ${progress.percent.toFixed(1)}%`
        });
        setUpdateStatusMessage(`ä¸‹è¼‰ä¸­... ${progress.percent.toFixed(1)}%`);
      });

      api.updater.onUpdateDownloaded((info) => {
        console.log('æ›´æ–°ä¸‹è¼‰å®Œæˆ (renderer):', info.version);
        setUpdateDownloaded(true);
        setUpdateProgress({ percent: 100, status: 'ä¸‹è¼‰å®Œæˆï¼Œç­‰å¾…å®‰è£' });
        setUpdateStatusMessage(`æ›´æ–° v${info.version} å·²ä¸‹è¼‰ï¼Œè«‹é»æ“Šå®‰è£`);
      });
    } else {
      setUpdateStatusMessage('ç›®å‰ç’°å¢ƒä¸æ”¯æ´è‡ªå‹•æ›´æ–°');
    }

  api?.app.getVersion()
      .then((version) => setAppVersion(version))
      .catch((error) => {
        console.warn('å–å¾—æ‡‰ç”¨ç‰ˆæœ¬å¤±æ•—:', error);
        setAppVersion('');
      });
  }, []);


  const handleCheckUpdates = async () => {
    const updater = window.electronAPI?.updater;
    if (!updater) {
      setUpdateStatusMessage('ç›®å‰ç’°å¢ƒä¸æ”¯æ´è‡ªå‹•æ›´æ–°');
      return;
    }

    try {
      setUpdateStatusMessage('æª¢æŸ¥æ›´æ–°ä¸­...');
      setUpdateProgress(null);
      const result = await updater.checkForUpdates();

      if (result?.available) {
        setUpdateAvailable(true);
        setUpdateDownloaded(false);
        setUpdateInfo({ version: result.version ?? '' });
        setUpdateStatusMessage(`ç™¼ç¾æ–°ç‰ˆæœ¬ ${result.version ?? ''}`.trim());
      } else {
        setUpdateAvailable(false);
        setUpdateDownloaded(false);
        setUpdateInfo(null);
        const message = result?.message || 'ç›®å‰å·²æ˜¯æœ€æ–°ç‰ˆæœ¬';
        setUpdateStatusMessage(message);
      }
    } catch (error) {
      setUpdateStatusMessage(`æª¢æŸ¥æ›´æ–°å¤±æ•—ï¼š${(error as Error).message}`);
    }
  };

  const handleDownloadUpdate = async () => {
    const updater = window.electronAPI?.updater;
    if (!updater) {
      setUpdateStatusMessage('ç›®å‰ç’°å¢ƒä¸æ”¯æ´è‡ªå‹•æ›´æ–°');
      return;
    }

    try {
      setUpdateStatusMessage('æº–å‚™ä¸‹è¼‰æ›´æ–°...');
      setUpdateProgress({ percent: 0, status: 'æº–å‚™ä¸‹è¼‰æ›´æ–°...' });
      const result = await updater.downloadUpdate();
      if (!result?.success) {
        const message = result?.error ? `ä¸‹è¼‰æ›´æ–°å¤±æ•—ï¼š${result.error}` : 'ä¸‹è¼‰æ›´æ–°å¤±æ•—';
        setUpdateStatusMessage(message);
        setUpdateProgress(null);
      }
    } catch (error) {
      setUpdateStatusMessage(`ä¸‹è¼‰æ›´æ–°å¤±æ•—ï¼š${(error as Error).message}`);
      setUpdateProgress(null);
    }
  };

  const handleInstallUpdate = async () => {
    const updater = window.electronAPI?.updater;
    if (!updater) {
      setUpdateStatusMessage('ç›®å‰ç’°å¢ƒä¸æ”¯æ´è‡ªå‹•æ›´æ–°');
      return;
    }

    try {
      setUpdateStatusMessage('æ‡‰ç”¨ç¨‹å¼å³å°‡é‡æ–°å•Ÿå‹•ä»¥å®‰è£æ›´æ–°...');
      await updater.installUpdate();
    } catch (error) {
      setUpdateStatusMessage(`å®‰è£æ›´æ–°å¤±æ•—ï¼š${(error as Error).message}`);
    }
  };


  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  const checkAudioPermission = async () => {
    try {
      const osStatus = await window.electronAPI?.permissions?.getMediaStatus?.('microphone');
      console.log('ğŸ” macOS systemPreferences éº¥å…‹é¢¨ç‹€æ…‹:', osStatus);

      switch (osStatus) {
        case 'authorized':
        case 'granted':
          setHasAudioPermission(true);
          setRecordingStatus('å·²ç²å¾—éº¥å…‹é¢¨æ¬Šé™ï¼Œæº–å‚™å°±ç·’');
          return;
        case 'denied':
          setHasAudioPermission(false);
          setRecordingStatus('éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼Œè«‹åœ¨ã€Œç³»çµ±è¨­å®š > éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ > éº¥å…‹é¢¨ã€å…è¨± Electron');
          await openSystemPreference('microphone');
          return;
        case 'not-determined':
        case 'prompt':
          setHasAudioPermission(null);
          console.log('ğŸ”” OS é¡¯ç¤ºå°šæœªæ±ºå®šï¼Œå˜—è©¦ askForMediaAccess');
          const granted = await requestMicrophoneAccess();
          if (granted) {
            setHasAudioPermission(true);
            setRecordingStatus('å·²å–å¾—éº¥å…‹é¢¨æ¬Šé™ï¼Œæº–å‚™å°±ç·’');
          } else {
            setRecordingStatus('ä»éœ€è¦æˆæ¬Šéº¥å…‹é¢¨æ¬Šé™');
          }
          return;
        default:
          console.warn('æœªçŸ¥çš„éº¥å…‹é¢¨æ¬Šé™ç‹€æ…‹:', osStatus);
          break;
      }

      // Fallbackï¼šç€è¦½å™¨å±¤ç´šæ¬Šé™ï¼ˆä¾‹å¦‚é macOS æˆ–ç³»çµ± API ä¸å¯ç”¨ï¼‰
      if (navigator.permissions && navigator.permissions.query) {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        console.log('ğŸ” Browser Permission API mic ç‹€æ…‹:', permissionStatus.state);

        if (permissionStatus.state === 'granted') {
          setHasAudioPermission(true);
          setRecordingStatus('å·²ç²å¾—éº¥å…‹é¢¨æ¬Šé™ï¼Œæº–å‚™å°±ç·’');
        } else if (permissionStatus.state === 'denied') {
          setHasAudioPermission(false);
          setRecordingStatus('éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼Œè«‹æª¢æŸ¥ç€è¦½å™¨/æ‡‰ç”¨è¨­å®š');
        } else {
          setHasAudioPermission(null);
          setRecordingStatus('éœ€è¦æˆæ¬Šéº¥å…‹é¢¨æ¬Šé™');
        }
      } else {
        console.log('ä¸æ”¯æ´ Permission APIï¼Œå°‡ç›´æ¥å˜—è©¦è¨ªå•');
        setRecordingStatus('æº–å‚™æ¸¬è©¦éº¥å…‹é¢¨...');
      }
    } catch (error) {
      console.error('æª¢æŸ¥æ¬Šé™æ™‚å‡ºéŒ¯:', error);
      setRecordingStatus('æ¬Šé™æª¢æŸ¥å¤±æ•—');
    }
  };

  const testAudioAccess = async () => {
    try {
      setRecordingStatus('æ­£åœ¨è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™...');
      let userMediaError: Error | null = null;

      try {
        const permissionStatus = navigator.permissions && await navigator.permissions.query({ name: 'microphone' as PermissionName });
        if (permissionStatus && permissionStatus.state === 'prompt') {
          await requestMicrophoneAccess();
        }
      } catch (permissionError) {
        console.warn('æŸ¥è©¢æˆ–è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™æ™‚å‡ºéŒ¯:', permissionError);
      }

      let stream: MediaStream | null = null;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (error) {
        userMediaError = error as Error;
      }

      if (!stream) {
        throw userMediaError ?? new Error('ç„¡æ³•å»ºç«‹éº¥å…‹é¢¨ä¸²æµ');
      }
      console.log('æˆåŠŸç²å¾—éŸ³è¨Šä¸²æµ:', stream);
      
      // æ¸¬è©¦å®Œæˆï¼Œç«‹å³é—œé–‰
      stream.getTracks().forEach(track => track.stop());
      
      setHasAudioPermission(true);
      setRecordingStatus('éº¥å…‹é¢¨æ¸¬è©¦æˆåŠŸï¼å¯ä»¥é–‹å§‹éŒ„éŸ³');
      return true;
    } catch (error) {
      console.error('ç„¡æ³•è¨ªå•éº¥å…‹é¢¨:', error);
      setHasAudioPermission(false);
      const err = error as DOMException;
      if (err?.name === 'NotAllowedError' || err?.name === 'SecurityError') {
        setRecordingStatus('éº¥å…‹é¢¨æ¬Šé™è¢« macOS æ‹’çµ•ï¼Œè«‹åœ¨ã€Œç³»çµ±è¨­å®š > éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ > éº¥å…‹é¢¨ã€å‹¾é¸ Electron å¾Œé‡å•Ÿæ‡‰ç”¨');
        await openSystemPreference('microphone');
        await requestMicrophoneAccess();
      } else {
        setRecordingStatus('ç„¡æ³•è¨ªå•éº¥å…‹é¢¨ï¼š' + err.message);
      }
      return false;
    }
  };

  // æ¸¬è©¦ç³»çµ±è²éŸ³æ¬Šé™ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
  const testSystemAudioAccess = async () => {
    try {
      setRecordingStatus('æ­£åœ¨æ¸¬è©¦ç³»çµ±è²éŸ³æ¬Šé™...');
      console.log('ğŸµ é–‹å§‹æ¸¬è©¦ç³»çµ±è²éŸ³æ¬Šé™...');
      const resolvedPlatform = platform === 'unknown' && /mac/i.test(navigator.userAgent)
        ? 'darwin'
        : platform;

      const result = await requestSystemAudioStream({
        platform: resolvedPlatform,
        preferDisplayCapture: true,
        logger: (message, data) => console.log(message, data ?? '')
      });

      result.warnings.forEach(warning => console.warn('âš ï¸ ç³»çµ±è²éŸ³è­¦å‘Š:', warning));

      if (result.stream) {
        stopStream(result.stream);
        setRecordingStatus('âœ… ç³»çµ±è²éŸ³æ¬Šé™æ¸¬è©¦æˆåŠŸï¼Œå¯æ“·å–ç³»çµ±éŸ³è¨Š');
        return true;
      }

      const hint = result.error || result.warnings[0] || 'ç³»çµ±è²éŸ³æ¬Šé™æ¸¬è©¦å¤±æ•—';
      setRecordingStatus(`âŒ ç³»çµ±è²éŸ³æ¬Šé™æ¸¬è©¦å¤±æ•—ï¼š${hint}`);
      if (/æ¬Šé™|å…è¨±|æˆæ¬Š/.test(hint)) {
        await openSystemPreference('screen');
      }
      return false;
      
    } catch (error) {
      console.error('âŒ æ¸¬è©¦éç¨‹éŒ¯èª¤:', error);
      setRecordingStatus('âŒ æ¸¬è©¦éŒ¯èª¤ï¼š' + (error as Error).message);
      return false;
    }
  };

  // åˆä½µéŸ³è¨Šæµ
  const startRecording = async () => {
    const activeStreams: MediaStream[] = [];
    let finalStream: MediaStream | null = null;

    try {
      setRecordingStatus('æ­£åœ¨å•Ÿå‹•éŒ„éŸ³...');
      
      cancelRecordingRef.current = false;

      const streams: MediaStream[] = [];
      
      // æ ¹æ“šéŒ„éŸ³æ¨¡å¼ç²å–å°æ‡‰çš„éŸ³è¨Šæµ
      if (recordingMode === 'microphone' || recordingMode === 'both') {
        setRecordingStatus('æ­£åœ¨ç²å–éº¥å…‹é¢¨æ¬Šé™...');
        const micStream = await requestMicrophoneStream();
        streams.push(micStream);
        activeStreams.push(micStream);
        setMicrophoneStream(micStream);
      }
      
      if (recordingMode === 'system' || recordingMode === 'both') {
        setRecordingStatus('æ­£åœ¨ç²å–ç³»çµ±è²éŸ³æ¬Šé™...');
        const resolvedPlatform = platform === 'unknown' && /mac/i.test(navigator.userAgent)
          ? 'darwin'
          : platform;

        const systemResult = await requestSystemAudioStream({
          platform: resolvedPlatform,
          preferDisplayCapture: resolvedPlatform === 'darwin',
          logger: (message, data) => console.log(message, data ?? '')
        });

        systemResult.warnings.forEach(warning => console.warn('âš ï¸ ç³»çµ±è²éŸ³è­¦å‘Š:', warning));

        if (systemResult.stream && systemResult.stream.getAudioTracks) {
          console.log('âœ… ç³»çµ±è²éŸ³æµæœ‰æ•ˆï¼Œè»Œé“æ•¸:', systemResult.stream.getAudioTracks().length);
          streams.push(systemResult.stream);
          activeStreams.push(systemResult.stream);
          setSystemStream(systemResult.stream);

          if (systemResult.source === 'display') {
            setRecordingStatus('å·²é€éè¢å¹•éŒ„è£½å–å¾—ç³»çµ±è²éŸ³');
          }
        } else if (recordingMode === 'system') {
          const reason = systemResult.error || 'ç„¡æ³•ç²å–ç³»çµ±è²éŸ³ä¾†æº';
          console.error('âŒ ç³»çµ±è²éŸ³æ“·å–å¤±æ•—:', reason);
          if (/Requested device not found/i.test(reason)) {
            const friendlyMessage = 'macOS ç›®å‰æœªæä¾›ç³»çµ±éŸ³è¨Šè¼¸å‡ºä¾†æºï¼›è‹¥éœ€éŒ„è£½ç³»çµ±è²éŸ³ï¼Œè«‹å®‰è£è™›æ“¬éŸ³è¨Šé©…å‹•ï¼ˆå¦‚ BlackHole æˆ– Loopbackï¼‰ä¸¦åœ¨åå¥½è¨­å®šä¸­æˆæ¬Šã€‚';
            setRecordingStatus(`ç³»çµ±è²éŸ³æ“·å–å¤±æ•—ï¼š${friendlyMessage}`);
            alert(friendlyMessage);
          } else if (/æ¬Šé™|å…è¨±|æˆæ¬Š/.test(reason)) {
            setRecordingStatus(`ç³»çµ±è²éŸ³æ“·å–å¤±æ•—ï¼š${reason}`);
            await openSystemPreference('screen');
          } else {
            setRecordingStatus(`ç³»çµ±è²éŸ³æ“·å–å¤±æ•—ï¼š${reason}`);
          }
          throw new Error(reason);
        } else {
          console.warn('âš ï¸ ç³»çµ±è²éŸ³ç²å–å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨éº¥å…‹é¢¨:', systemResult.error);
          if (systemResult.error) {
            let fallbackMessage = systemResult.error;
            if (/Requested device not found/i.test(systemResult.error)) {
              fallbackMessage = 'macOS å°šæœªåµæ¸¬åˆ°å¯éŒ„è£½çš„ç³»çµ±éŸ³è¨Šä¾†æºï¼Œå°‡åƒ…éŒ„è£½éº¥å…‹é¢¨ã€‚å¯è€ƒæ…®å®‰è£è™›æ“¬éŸ³è¨Šé©…å‹•ï¼ˆä¾‹å¦‚ BlackHoleï¼‰ã€‚';
            }
            setRecordingStatus(`ç³»çµ±è²éŸ³å–å¾—å¤±æ•—ï¼š${fallbackMessage}`);
            if (/æ¬Šé™|å…è¨±|æˆæ¬Š/.test(systemResult.error)) {
              await openSystemPreference('screen');
            }
          }
        }
      }
      
      if (streams.length === 0) {
        throw new Error('ç„¡æ³•ç²å–ä»»ä½•éŸ³è¨Šæº');
      }
      
      // å¦‚æœæœ‰å¤šå€‹éŸ³è¨Šæµï¼Œåˆä½µå®ƒå€‘
      if (streams.length > 1) {
        setRecordingStatus('æ­£åœ¨åˆä½µéŸ³è¨Šæº...');
        finalStream = mergeMediaStreams(streams);
        activeStreams.push(finalStream);
      } else {
        finalStream = streams[0];
      }
      
      if (!finalStream || !finalStream.getAudioTracks) {
        console.error('âŒ æœ€çµ‚éŸ³è¨Šä¸²æµç„¡æ•ˆ:', finalStream);
        throw new Error('éŸ³è¨Šä¸²æµåˆä½µå¤±æ•— - ç„¡æ•ˆçš„ MediaStream');
      }

      console.log('æœ€çµ‚éŸ³è¨Šä¸²æµï¼Œè»Œé“æ•¸:', finalStream.getAudioTracks().length);

      const recorder = new MediaRecorder(finalStream);
      const chunks: Blob[] = [];
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
          console.log('æ”¶åˆ°éŸ³è¨Šæ•¸æ“š:', event.data.size, 'ä½å…ƒçµ„');
        }
      };

      recorder.onstop = async () => {
        console.log('éŒ„éŸ³åœæ­¢ï¼Œç¸½å…±', chunks.length, 'å€‹éŸ³è¨Šç‰‡æ®µ');
        const wasCancelled = cancelRecordingRef.current;

        // æ¸…ç†æ‰€æœ‰éŸ³è¨Šæµ
        activeStreams.forEach(stream => {
          console.log('é—œé–‰éŸ³è¨Šä¸²æµ');
          stopStream(stream);
        });

        setSystemStream(null);
        setMicrophoneStream(null);
        setIsRecording(false);

        if (wasCancelled) {
          setAudioChunks([]);
          setRecordingStatus('å·²å–æ¶ˆéŒ„éŸ³ï¼Œæœªä¿å­˜ä»»ä½•æª”æ¡ˆ');
          return;
        }

        const audioBlob = new Blob(chunks, { type: 'audio/webm;codecs=opus' });
        console.log('æœ€çµ‚éŸ³è¨Šæª”æ¡ˆå¤§å°:', audioBlob.size, 'ä½å…ƒçµ„');
        
        // ç”Ÿæˆæª”å
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
        const modeLabel = recordingMode === 'both' ? 'mixed' : recordingMode === 'system' ? 'system' : 'mic';
        const mode = settings.transcriptionMode || (settings.useGemini ? 'gemini_direct' : 'hybrid_stt');
        const filenameBase = `meeting-${modeLabel}-${timestamp}`;
        const filename = `${filenameBase}.wav`;
        
        try {
          // ä¸€å¾‹ï¼šWebM â†’ WAVï¼ˆæœ¬åœ°ä¿å­˜ï¼‰ï¼Œç¢ºä¿å¯æ’­æ”¾
          let savedPath = '';
          let tempWebmPath: string | null = null;
          const tempDirResult = await window.electronAPI.recording.getTempDir();
          const tempDir = tempDirResult.success && tempDirResult.tempDir ? tempDirResult.tempDir : undefined;
          if (!tempDir) throw new Error('ç„¡æ³•å–å¾—æš«å­˜ç›®éŒ„');
          tempWebmPath = joinPath(tempDir, `${filenameBase}.webm`);
          await window.electronAPI.recording.saveBlob(tempWebmPath, await audioBlob.arrayBuffer());
          const prep = await window.electronAPI.stt.prepareAudio({ sourcePath: tempWebmPath, mimeType: 'audio/webm', sampleRate: 16_000 });
          if (!prep.success || !prep.wavPath) throw new Error(prep.error || 'WAV è½‰æª”å¤±æ•—');
          const wavPathTemp = prep.wavPath;
          let baseDirectory: string | undefined;
          const preferred = settings.recordingSavePath?.trim();
          if (preferred) {
            if (preferred.startsWith('~/')) {
              const homePath = await window.electronAPI.app.getPath('home');
              const relative = preferred.slice(2);
              baseDirectory = joinPath(homePath, relative);
            } else if (!preferred.startsWith('~')) {
              baseDirectory = preferred;
            }
          }
          if (!baseDirectory) {
            baseDirectory = await window.electronAPI.app.getPath('downloads');
          }
          const normalizedBase = normalizePath(baseDirectory);
          const wavFilename = `${filenameBase}.wav`;
          const destPath = joinPath(normalizedBase, wavFilename);
          const copyRes = await window.electronAPI.recording.copyFile(wavPathTemp, destPath);
          if (!copyRes.success) throw new Error(copyRes.error || 'WAV å„²å­˜å¤±æ•—');
          savedPath = destPath;
          
          const newRecording = {
            id: Date.now().toString(),
            filename,
            blob: audioBlob,
            timestamp: new Date().toLocaleString('zh-TW'),
            duration: recordingTime,
            size: audioBlob.size,
            filePath: savedPath,
            chunks: [...chunks]
          };
          
          setRecordings(prev => [newRecording, ...prev]);
          setRecordingStatus(`éŒ„éŸ³å®Œæˆï¼æª”æ¡ˆå·²è‡ªå‹•ä¿å­˜: ${filename} (${(audioBlob.size / 1024).toFixed(1)} KB)`);
          setAudioChunks([...chunks]);
          
          // äº¤çµ¦è½‰éŒ„ä½œæ¥­ï¼ˆä»å‚³é WebM blob æ–¹ä¾¿åˆ‡æ®µï¼›ä½œæ¥­å…§æœƒåšåˆ‡æ®µèˆ‡è½‰æª”ï¼‰
          startTranscriptionJob(audioBlob, filename, [...chunks], recordingTime, { sourcePath: tempWebmPath || savedPath });
        } catch (error) {
          console.error('éŒ„éŸ³ä¿å­˜å¤±æ•—:', error);
          setRecordingStatus('éŒ„éŸ³ä¿å­˜å¤±æ•—: ' + (error as Error).message);
        }
      };

      recorder.onerror = (event) => {
        console.error('éŒ„éŸ³éŒ¯èª¤:', event);
        setRecordingStatus('éŒ„éŸ³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤');
      };

      setAudioChunks([]);
      setMediaRecorder(recorder);
      recorder.start(1000); // æ¯ç§’æ”¶é›†ä¸€æ¬¡æ•¸æ“š
      setIsRecording(true);
      setRecordingTime(0);
      
      const modeText = recordingMode === 'both' ? 'ç³»çµ±è²éŸ³ + éº¥å…‹é¢¨' : 
                      recordingMode === 'system' ? 'ç³»çµ±è²éŸ³' : 'éº¥å…‹é¢¨';
      setRecordingStatus(`éŒ„éŸ³ä¸­ (${modeText})...`);
      console.log('é–‹å§‹éŒ„éŸ³ï¼ŒMediaRecorder ç‹€æ…‹:', recorder.state);
    } catch (error) {
      console.error('å•Ÿå‹•éŒ„éŸ³å¤±æ•—:', error);
      setRecordingStatus('å•Ÿå‹•éŒ„éŸ³å¤±æ•—ï¼š' + (error as Error).message);
      alert('éŒ„éŸ³å•Ÿå‹•å¤±æ•—ï¼š' + (error as Error).message);
      activeStreams.forEach(stream => stopStream(stream));
      setSystemStream(null);
      setMicrophoneStream(null);
    }
  };

  const cancelRecording = () => {
    if (!mediaRecorder || mediaRecorder.state === 'inactive') {
      setRecordingStatus('ç›®å‰æ²’æœ‰é€²è¡Œä¸­çš„éŒ„éŸ³');
      return;
    }

    cancelRecordingRef.current = true;
    setRecordingStatus('æ­£åœ¨å–æ¶ˆéŒ„éŸ³...');
    try {
      mediaRecorder.stop();
      setIsRecording(false);
      setMediaRecorder(null);
      setTimeout(() => {
        stopStream(systemStream);
        stopStream(microphoneStream);
        setSystemStream(null);
        setMicrophoneStream(null);
      }, 500);
    } catch (error) {
      console.error('å–æ¶ˆéŒ„éŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤:', error);
      setRecordingStatus('å–æ¶ˆéŒ„éŸ³å¤±æ•—ï¼š' + (error as Error).message);
      cancelRecordingRef.current = false;
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('æ­£åœ¨åœæ­¢éŒ„éŸ³...');
      mediaRecorder.stop();
      setIsRecording(false);
      setMediaRecorder(null);
      console.log('éŒ„éŸ³çµæŸï¼Œç¸½æ™‚é•·:', formatTime(recordingTime));
      
      // ç«‹å³æ¸…ç†éŸ³è¨Šæµï¼ˆé˜²æ­¢éŒ„éŸ³çµæŸå‰å°±æ¸…ç†ï¼‰
      setTimeout(() => {
        stopStream(systemStream);
        stopStream(microphoneStream);
        setSystemStream(null);
        setMicrophoneStream(null);
      }, 1000);
    } else {
      console.log('MediaRecorder ç‹€æ…‹ç•°å¸¸:', mediaRecorder?.state);
      setRecordingStatus('åœæ­¢éŒ„éŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤');
    }
  };

  const downloadRecording = (recording: typeof recordings[0]) => {
    const audioUrl = URL.createObjectURL(recording.blob);
    const downloadLink = document.createElement('a');
    downloadLink.href = audioUrl;
    downloadLink.download = recording.filename;
    downloadLink.style.display = 'none';
    document.body.appendChild(downloadLink);
    downloadLink.click();
    document.body.removeChild(downloadLink);
    URL.revokeObjectURL(audioUrl);
  };

  // è‡ªå‹•ä¿å­˜éŒ„éŸ³æª”æ¡ˆ
  const saveRecordingFile = async (blob: Blob, filename: string): Promise<string> => {
    try {
      console.log(`ğŸµ é–‹å§‹å„²å­˜éŒ„éŸ³æª”æ¡ˆ: ${filename}`);
      console.log('ğŸ“ æª”æ¡ˆå¤§å°:', blob.size, 'ä½å…ƒçµ„');

      // ç¢ºå®šå„²å­˜è·¯å¾‘
      let baseDirectory: string | undefined;
      const preferred = settings.recordingSavePath?.trim();

      if (preferred) {
        if (preferred.startsWith('~/')) {
          const homePath = await window.electronAPI.app.getPath('home');
          const relative = preferred.slice(2);
          baseDirectory = joinPath(homePath, relative);
          console.log('ğŸ“ ä½¿ç”¨å®¶ç›®éŒ„ç›¸å°è·¯å¾‘å„²å­˜:', baseDirectory);
        } else if (!preferred.startsWith('~')) {
          baseDirectory = preferred;
          console.log('ğŸ“ ä½¿ç”¨è¨­å®šçš„å„²å­˜è·¯å¾‘:', baseDirectory);
        }
      }

      if (!baseDirectory) {
        baseDirectory = await window.electronAPI.app.getPath('downloads');
        console.log('ğŸ“ ä½¿ç”¨é è¨­ä¸‹è¼‰è·¯å¾‘:', baseDirectory);
      }

      const normalizedBase = normalizePath(baseDirectory);
      const fullPath = joinPath(normalizedBase, filename);
      console.log('ğŸ¯ å®Œæ•´å„²å­˜è·¯å¾‘:', fullPath);

      // è½‰æ›ç‚º ArrayBuffer ä¸¦å„²å­˜
      console.log('ğŸ”„ è½‰æ›æª”æ¡ˆæ ¼å¼...');
      const buffer = await blob.arrayBuffer();
      console.log('ğŸ’¾ é–‹å§‹å¯«å…¥æª”æ¡ˆ...');

      const result = await window.electronAPI.recording.saveBlob(fullPath, buffer);
      console.log('âœ… saveBlob å›æ‡‰:', result);

      console.log('ğŸ‰ æª”æ¡ˆå„²å­˜æˆåŠŸï¼è·¯å¾‘:', fullPath);
      return fullPath;
    } catch (error) {
      console.error('âŒ æª”æ¡ˆå„²å­˜éç¨‹å‡ºéŒ¯:', error);
      console.error('âŒ éŒ¯èª¤è©³æƒ…:', (error as Error).message);
      console.error('âŒ éŒ¯èª¤å †ç–Š:', (error as Error).stack);
      throw error;
    }
  };

  const playRecording = (recording: typeof recordings[0]) => {
    const audioUrl = URL.createObjectURL(recording.blob);
    const audio = new Audio(audioUrl);
    audio.play().catch(e => console.log('æ’­æ”¾å¤±æ•—:', e));
  };

  // å•Ÿå‹•è½‰éŒ„ä½œæ¥­
  const startTranscriptionJob = async (
    audioBlob: Blob,
    filename: string,
    originalChunks: Blob[] = [],
    durationSeconds: number = recordingTime,
    options: { sourcePath?: string } = {}
  ) => {
    // é˜²æ­¢é‡è¤‡åŸ·è¡Œï¼šæª¢æŸ¥æ˜¯å¦å·²ç¶“åœ¨è™•ç†ç›¸åŒæª”æ¡ˆ
    if (processingJobs.has(filename)) {
      console.log('âš ï¸ è½‰éŒ„ä»»å‹™å·²åœ¨é€²è¡Œä¸­ï¼Œè·³éé‡è¤‡åŸ·è¡Œ:', filename);
      return;
    }
    
    // æ¨™è¨˜ç‚ºè™•ç†ä¸­
    setProcessingJobs(prev => new Set([...prev, filename]));
    
    let jobId: string | null = null;

    try {
      console.log('é–‹å§‹è½‰éŒ„æµç¨‹:', filename);
      
      // å‰µå»ºä½œæ¥­è¨˜éŒ„
      jobId = Date.now().toString();
      const newJob = {
        id: jobId,
        meetingId: jobId, // ä½¿ç”¨ jobId ä½œç‚º meetingId
        filename: filename,
        title: filename, // ä½¿ç”¨æª”æ¡ˆåä½œç‚ºæ¨™é¡Œ
        participants: [], // éŒ„éŸ³æ²’æœ‰åƒèˆ‡è€…ä¿¡æ¯
        status: 'queued' as const,
        progress: 0,
        createdAt: new Date().toLocaleString('zh-TW'),
        audioFile: options.sourcePath,
        progressMessage: JOB_STATUS_HINTS.queued
      };
      
      addJob(newJob);
      
      const mode = settings.transcriptionMode || (settings.useGemini ? 'gemini_direct' : 'hybrid_stt');

      if (mode === 'hybrid_stt') {
        console.log('ä½¿ç”¨ Google STT + Gemini æ··åˆæ¨¡å¼é€²è¡Œè½‰éŒ„');
        await startHybridSTTTranscription(audioBlob, filename, jobId, originalChunks, durationSeconds);
      } else if (settings.useGemini) {
        if (!settings.geminiApiKey) {
          alert('è«‹å…ˆåœ¨è¨­å®šä¸­é…ç½® Gemini API Key æ‰èƒ½ä½¿ç”¨è½‰éŒ„åŠŸèƒ½');
          return;
        }
        console.log('ä½¿ç”¨ Google Gemini API é€²è¡Œè½‰éŒ„');
        await startGeminiTranscription(audioBlob, filename, jobId, originalChunks, durationSeconds);
      } else {
        alert('è«‹å…ˆåœ¨è¨­å®šä¸­é…ç½®è½‰éŒ„æœå‹™æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½');
        return;
      }
      
    } catch (error) {
      console.error('è½‰éŒ„æµç¨‹å•Ÿå‹•å¤±æ•—:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (jobId) {
        const latestJob = useJobsStore.getState().jobs.find(job => job.id === jobId);
        if (latestJob) {
          updateJob(jobId, {
            status: 'failed',
            progressMessage: `${JOB_STATUS_HINTS.failed}ï¼š${errorMessage}`,
            errorMessage
          });
        }
      }
      setRecordingStatus('è½‰éŒ„å•Ÿå‹•å¤±æ•—: ' + errorMessage);
    } finally {
      // æ¸…é™¤è™•ç†ç‹€æ…‹ï¼Œå…è¨±é‡æ–°åŸ·è¡Œ
      setProcessingJobs(prev => {
        const newSet = new Set(prev);
        newSet.delete(filename);
        return newSet;
      });
    }
  };

  const handleDeleteJob = async (jobId: string) => {
    const targetJob = jobs.find(job => job.id === jobId);
    if (!targetJob) {
      return;
    }

    const confirmMessage = `ç¢ºå®šè¦åˆªé™¤ã€Œ${targetJob.filename}ã€çš„è½‰éŒ„çµæœå—ï¼Ÿ` +
      (targetJob.audioFile ? '\n\né€™æœƒä¸€ä½µç§»é™¤æœ¬åœ°éŒ„éŸ³æª”æ¡ˆï¼š\n' + targetJob.audioFile : '');

    if (!window.confirm(confirmMessage)) {
      return;
    }

    let fileRemovalError: Error | null = null;

    if (targetJob.audioFile) {
      try {
        const cleanupResult = await window.electronAPI?.recording?.cleanup([targetJob.audioFile]);
        if (cleanupResult && cleanupResult.success === false) {
          fileRemovalError = new Error(cleanupResult.error || 'éŒ„éŸ³æª”æ¡ˆåˆªé™¤å¤±æ•—');
        }
      } catch (error) {
        console.error('åˆªé™¤éŒ„éŸ³æª”æ¡ˆå¤±æ•—:', error);
        fileRemovalError = error instanceof Error ? error : new Error(String(error));
      }
    }

    removeJob(jobId);
    setRecordings(prev => prev.filter(recording => recording.filePath !== targetJob.audioFile));

    if (fileRemovalError) {
      alert(`å·²ç§»é™¤è½‰éŒ„çµæœï¼Œä½†åˆªé™¤éŒ„éŸ³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š${fileRemovalError.message}`);
    } else {
      alert('å·²åˆªé™¤è½‰éŒ„çµæœã€‚');
    }
  };

  const startHybridSTTTranscription = async (
    audioBlob: Blob,
    filename: string,
    jobId: string,
    originalChunks: Blob[] = [],
    durationSeconds: number = recordingTime
  ) => {
    const currentSettings = useSettingsStore.getState().settings;
    const sttSettings = currentSettings.googleCloudSTT;
    let cleanupPaths: string[] = [];

    try {
      if (!sttSettings || !sttSettings.enabled) {
        throw new Error('è«‹å…ˆåœ¨è¨­å®šé å•Ÿç”¨ä¸¦é…ç½® Google STT');
      }

      const missingFields: string[] = [];
      if (!sttSettings.projectId) missingFields.push('Project ID');
      if (!sttSettings.location) missingFields.push('Location');
      if (!sttSettings.recognizerId) missingFields.push('Recognizer ID');
      if (!sttSettings.keyFilePath) missingFields.push('Service Account Key æª”æ¡ˆ');
      if (missingFields.length > 0) {
        throw new Error(`Google STT è¨­å®šä¸å®Œæ•´ï¼š${missingFields.join('ã€')}`);
      }

      const geminiKey = getGeminiKey(currentSettings);
      if (!geminiKey) {
        throw new Error('è«‹å…ˆè¨­å®š API é‡‘é‘°ï¼Œä»¥ä¾¿é€²è¡Œå¾ŒçºŒæ‘˜è¦èˆ‡å¾Œè™•ç†');
      }

      const geminiClient = new GeminiAPIClient(geminiKey, {
        preferredModel: currentSettings.geminiPreferredModel,
        enableFallback: currentSettings.geminiEnableFallback,
        retryConfig: currentSettings.geminiRetryConfig,
        diagnosticMode: currentSettings.geminiDiagnosticMode
      });

      setRecordingStatus('åˆå§‹åŒ– Google STT æœå‹™...');
      const initResult = await window.electronAPI.stt.initialize({
        projectId: sttSettings.projectId!,
        location: sttSettings.location!,
        recognizerId: sttSettings.recognizerId!,
        keyFilePath: sttSettings.keyFilePath!,
        model: sttSettings.model
      });

      if (!initResult.success) {
        throw new Error(initResult.error || 'Google STT åˆå§‹åŒ–å¤±æ•—');
      }

      const tempDirResult = await window.electronAPI.recording.getTempDir();
      if (!tempDirResult.success || !tempDirResult.tempDir) {
        throw new Error(tempDirResult.error || 'ç„¡æ³•å–å¾—æš«å­˜ç›®éŒ„');
      }
      const tempDir = tempDirResult.tempDir;

      cleanupPaths = [];
      const baseMime = normalizeMimeType(audioBlob.type) || 'audio/webm';
      const baseExt = inferExtensionFromMime(baseMime);
      const sourceFilePath = joinPath(tempDir, `${jobId}-source.${baseExt}`);

      setRecordingStatus('ä¿å­˜åŸå§‹éŸ³è¨Šæª”æ¡ˆ...');
      const originalBuffer = await audioBlob.arrayBuffer();
      const saveOriginalResult = await window.electronAPI.recording.saveBlob(sourceFilePath, originalBuffer);
      if (!saveOriginalResult.success) {
        throw new Error(saveOriginalResult.error || 'åŸå§‹éŸ³è¨Šå„²å­˜å¤±æ•—');
      }
      cleanupPaths.push(sourceFilePath);

      setRecordingStatus('è½‰æ›éŸ³è¨Šæ ¼å¼ï¼Œæº–å‚™åˆ‡å‰²...');
      const prepareResult = await window.electronAPI.stt.prepareAudio({
        sourcePath: sourceFilePath,
        mimeType: baseMime,
        sampleRate: 16_000
      });
      if (!prepareResult.success || !prepareResult.wavPath) {
        throw new Error(prepareResult.error || 'éŸ³è¨Šæ ¼å¼è½‰æ›å¤±æ•—');
      }

      const preparedWavPath = prepareResult.wavPath;
      cleanupPaths.push(preparedWavPath);

      // æ±ºå®šåˆ‡æ®µæ‰€ç”¨çš„ç¸½æ™‚é•·ï¼šä»¥ä¸»ç¨‹åº ffprobe å›å‚³ç‚ºä¸»ï¼Œå¾Œå‚™ä»¥ <audio> ä¼°ç®—
      let durationForSegments = prepareResult.durationSeconds && prepareResult.durationSeconds > 0
        ? prepareResult.durationSeconds
        : (durationSeconds || 0);
      if (!durationForSegments || durationForSegments <= 0) {
        try {
          durationForSegments = await getBlobDuration(audioBlob);
        } catch {}
      }
      const sttSegments = createSTTAudioSegments(audioBlob, originalChunks, Math.max(1, Math.floor(durationForSegments)));
      console.log('ğŸ“¼ Google STT åˆ†æ®µè³‡è¨Š:', sttSegments.map(s => ({ index: s.index + 1, duration: s.duration })));

      const aggregatedSegments: STTTranscriptSegment[] = [];
      const transcriptParts: string[] = [];

      const recognizerIdLower = (sttSettings.recognizerId || '').toLowerCase();
      const modelIdLower = (sttSettings.model || '').toLowerCase();
      const isChirp3 = modelIdLower.includes('chirp_3') || recognizerIdLower.includes('chirp_3');
      // èªè¨€ï¼šchirp_3 å¼·åˆ¶ç”¨ç°¡ä¸­ï¼›å…¶ä»–ä½¿ç”¨ä½¿ç”¨è€…è¨­å®š
      const langForThisRun = isChirp3 ? 'cmn-Hans-CN' : (sttSettings.languageCode || 'zh-TW');
      // åƒ…åœ¨æ¨¡å‹ç‚º chirp_3 ä¸”èªè¨€ç‚ºç°¡ä¸­æ™‚é–‹å•Ÿ diarization
      let enableSpeakerDiarization = Boolean(sttSettings.enableSpeakerDiarization) && isChirp3 && langForThisRun === 'cmn-Hans-CN';
      if (!enableSpeakerDiarization && Boolean(sttSettings.enableSpeakerDiarization) && (!isChirp3 || langForThisRun !== 'cmn-Hans-CN')) {
        console.warn('Diarization åƒ…æ”¯æ´ chirp_3 + cmn-Hans-CNï¼Œæœ¬æ¬¡å·²è‡ªå‹•åœç”¨ã€‚');
        setRecordingStatus('Diarization åƒ…æ”¯æ´ chirp_3 + ç°¡ä¸­ (cmn-Hans-CN)ï¼Œæœ¬æ¬¡å·²è‡ªå‹•åœç”¨ã€‚');
      }

      // åˆå§‹åŒ–çœŸå¯¦é€²åº¦ä¼°ç®—
      const totalSecondsForStt = sttSegments.reduce((sum, s) => sum + (s.duration || (s.end - s.start) || 0), 0);
      progressEstRef.current[jobId] = { startTs: Date.now(), totalSeconds: Math.max(totalSecondsForStt, 1), processedSeconds: 0, lastEmitTs: 0 };

      window.electronAPI.stt.onProgress(event => {
        if (event.message) {
          // åƒ…æ›´æ–°æœ¬åœ°ç‹€æ…‹æç¤ºï¼Œé¿å…å¹²æ“¾ä½¿ç”¨è€…å¯è®€çš„ç©©å®šè¨Šæ¯
          setRecordingStatus(event.message);
        }
        if (typeof event.progress === 'number') {
          // æˆ‘å€‘ç”¨çœŸå¯¦ä¼°ç®—ç‚ºä¸»ï¼Œé€™è£¡ä¸ç›´æ¥è¦†è“‹ç™¾åˆ†æ¯”ï¼Œåƒ…åœ¨éå¸¸æ—©æœŸæä¾›æœ€ä½é€²åº¦
          const normalized = Math.min(25, Math.max(event.progress, 3));
          updateJob(jobId, { progress: normalized });
        }
      });

      updateJob(jobId, { status: 'stt', progress: 10 });
      setRecordingStatus(`é–‹å§‹é€²è¡Œ Google STT è½‰éŒ„ï¼Œå…± ${sttSegments.length} æ®µ`);

      for (const segment of sttSegments) {
        const partLabel = sttSegments.length > 1
          ? `ç¬¬ ${segment.index + 1}/${sttSegments.length} æ®µï¼ˆç´„ ${Math.round(segment.start)}s ~ ${Math.round(segment.end)}sï¼‰`
          : 'æ•´æ®µéŸ³è¨Š';

        setRecordingStatus(`Google STT æ­£åœ¨è™•ç† ${partLabel}...`);

          const sttResponse: STTTranscriptionResponse = await window.electronAPI.stt.transcribe({
            sourcePath: preparedWavPath,
            startTimeSeconds: segment.start,
            endTimeSeconds: segment.end,
            languageCode: langForThisRun,
            enableWordTimeOffsets: !isChirp3,
            enableSpeakerDiarization: enableSpeakerDiarization,
            minSpeakerCount: enableSpeakerDiarization ? (sttSettings.minSpeakerCount ?? 1) : undefined,
            maxSpeakerCount: enableSpeakerDiarization ? (sttSettings.maxSpeakerCount ?? 6) : undefined,
            mimeType: 'audio/wav'
          });

        if (!sttResponse.success || !sttResponse.transcript) {
          throw new Error(sttResponse.error || 'Google STT è½‰éŒ„å¤±æ•—');
        }

        if (Array.isArray(sttResponse.segments)) {
          aggregatedSegments.push(...sttResponse.segments);
        }

        transcriptParts.push(sttResponse.transcript);

        // æŒ‰å·²å®Œæˆåª’é«”ç§’æ•¸æ›´æ–°çœŸå¯¦é€²åº¦èˆ‡ ETA
        const est = progressEstRef.current[jobId];
        if (est) {
          const d = segment.duration || (segment.end - segment.start) || 0;
          est.processedSeconds = Math.min(est.totalSeconds, est.processedSeconds + Math.max(d, 0));
          safeUpdateJobProgress(jobId, est.processedSeconds, est.totalSeconds, 'èªéŸ³è½‰æ–‡å­—è™•ç†ä¸­');
        }
      }

      let formattedSegments: TranscriptSegment[] = [];
      let transcriptFromSegments = '';

      if (aggregatedSegments.length > 0) {
        const built = buildTranscriptFromSTTSegments(aggregatedSegments);
        formattedSegments = built.formattedSegments;
        transcriptFromSegments = built.text;
      }

      let finalTranscript = transcriptParts.join('\n\n').trim();

      if (!finalTranscript) {
        finalTranscript = transcriptFromSegments;
      }

      if ((!formattedSegments || formattedSegments.length === 0) && finalTranscript) {
        formattedSegments = sttSegments.map((segment, idx) => ({
          start: segment.start,
          end: segment.end,
          speaker: `Segment ${idx + 1}`,
          text: (transcriptParts[idx] || finalTranscript)
            .replace(/\s+/g, ' ')
            .trim()
        }));
      }

      if (!finalTranscript) {
        throw new Error('ç„¡æ³•å–å¾— Google STT è½‰éŒ„çµæœ');
      }

      if (currentSettings.vocabularyList && currentSettings.vocabularyList.length > 0) {
        finalTranscript = VocabularyService.applyVocabularyCorrections(finalTranscript, currentSettings.vocabularyList);
      }

      setRecordingStatus('Google STT å®Œæˆï¼Œå•Ÿå‹• Gemini é€å­—ç¨¿ä¿®æ­£...');
      const estAfterStt = progressEstRef.current[jobId];
      if (estAfterStt) safeUpdateJobProgress(jobId, Math.max(estAfterStt.processedSeconds, estAfterStt.totalSeconds * 0.9), estAfterStt.totalSeconds, 'é€å­—ç¨¿ä¿®æ­£ä¸­');
      updateJob(jobId, { status: 'stt' });

      let cleanedTranscript = await cleanupTranscriptInChunks(
        geminiClient,
        finalTranscript,
        currentSettings.customTranscriptCleanupPrompt
      );

      // ç°¡é«” â†’ ç¹é«”ï¼ˆå°ç£ï¼‰
      try {
        const { toTW } = await import('./utils/zhConvert');
        cleanedTranscript = await toTW(cleanedTranscript);
      } catch {}

      if (!cleanedTranscript) {
        throw new Error('é€å­—ç¨¿ä¿®æ­£å¾Œçš„å…§å®¹ç‚ºç©º');
      }

      finalTranscript = cleanedTranscript;
      formattedSegments = mergeSegmentsWithCleanTranscript(formattedSegments, finalTranscript);

      setRecordingStatus('é€å­—ç¨¿ä¿®æ­£å®Œæˆï¼Œæº–å‚™ç”Ÿæˆæœƒè­°æ‘˜è¦...');
      if (estAfterStt) safeUpdateJobProgress(jobId, Math.max(estAfterStt.processedSeconds, estAfterStt.totalSeconds * 0.95), estAfterStt.totalSeconds, 'ç”Ÿæˆæœƒè­°æ‘˜è¦');
      updateJob(jobId, { status: 'summarize' });

      let summaryMarkdown = '';
      let overallSummary = '';

      if (currentSettings.customSummaryPrompt) {
        const summaryText = await geminiClient.generateCustomSummary(cleanedTranscript, currentSettings.customSummaryPrompt);
        summaryMarkdown = summaryText;
        overallSummary = summaryText;
      } else {
        const structuredSummary = await geminiClient.generateStructuredSummaryFromTranscript(cleanedTranscript);
        // è½‰ç¹
        try {
          const { toTW } = await import('./utils/zhConvert');
          summaryMarkdown = await toTW(structuredSummary.minutesMd || '');
        } catch {
          summaryMarkdown = structuredSummary.minutesMd;
        }
        overallSummary = structuredSummary.overallSummary;
      }

      // ç”¢ç”Ÿã€Œæ¨™é¡Œå¼å¤§ç¶±ã€çš„æ™‚é–“è»¸ï¼ˆå¯é»æ“Šè·³åˆ°é€å­—ç¨¿ï¼‰
      let timelineItems: Array<{ time?: string; item: string; desc?: string }> = [];
      try {
        const tl = await geminiClient.generateTimelineOutline(
          (formattedSegments || []).map(s => ({ start: typeof s.start === 'number' ? s.start : 0, end: typeof s.end === 'number' ? s.end : undefined, text: s.text }))
        );
        // ç°¡â†’ç¹
        try {
          const { toTW } = await import('./utils/zhConvert');
          timelineItems = await Promise.all((tl || []).map(async (t: any) => ({ time: t.time, item: await toTW(t.item || ''), desc: t.desc ? await toTW(t.desc) : undefined })));
        } catch {
          timelineItems = (tl || []).map((t: any) => ({ time: t.time, item: t.item, desc: t.desc }));
        }
      } catch (e) {
        console.warn('ç”¢ç”Ÿæ™‚é–“è»¸å¤§ç¶±å¤±æ•—ï¼ˆå°‡ä»¥ç©ºç™½ç•¥éï¼‰:', e);
      }

      updateJob(jobId, { status: 'done', transcript: cleanedTranscript, transcriptSegments: formattedSegments, summary: summaryMarkdown, timelineItems });
      if (estAfterStt) safeUpdateJobProgress(jobId, estAfterStt.totalSeconds, estAfterStt.totalSeconds, 'å®Œæˆ');

      setRecordingStatus('Google STT è½‰éŒ„å®Œæˆï¼å¯åœ¨çµæœé æŸ¥çœ‹è©³ç´°å…§å®¹');

    } catch (error) {
      console.error('Google STT è½‰éŒ„å¤±æ•—:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      updateJob(jobId, {
        status: 'failed',
        errorMessage,
        progressMessage: `${JOB_STATUS_HINTS.failed}ï¼š${errorMessage}`
      });
      setRecordingStatus('Google STT è½‰éŒ„å¤±æ•—ï¼š' + errorMessage);
    } finally {
      if (cleanupPaths.length > 0) {
        window.electronAPI.recording.cleanup(cleanupPaths).catch(() => void 0);
      }
    }
  };

  // ä½¿ç”¨ Gemini API é€²è¡Œè½‰éŒ„
  const startGeminiTranscription = async (
    audioBlob: Blob,
    filename: string,
    jobId: string,
    originalChunks: Blob[] = [],
    durationSeconds: number = recordingTime
  ) => {
    try {
      // ç›´æ¥ä½¿ç”¨æœ€æ–°çš„è¨­å®šï¼Œä¸ç­‰å¾… hydration ç‹€æ…‹
      const currentSettings = useSettingsStore.getState().settings;
      const geminiKey = getGeminiKey(currentSettings);
      console.log('ğŸ” é–‹å§‹ Gemini è½‰éŒ„ï¼Œç•¶å‰è¨­å®š:', {
        hasApiKey: !!geminiKey,
        useGemini: currentSettings.useGemini,
        apiKeyPrefix: geminiKey?.substring(0, 10)
      });
      
      if (!geminiKey) {
        throw new Error('è«‹å…ˆè¨­å®š API é‡‘é‘°');
      }
      
      const geminiClient = new GeminiAPIClient(geminiKey, {
        preferredModel: currentSettings.geminiPreferredModel,
        enableFallback: currentSettings.geminiEnableFallback,
        retryConfig: currentSettings.geminiRetryConfig,
        diagnosticMode: currentSettings.geminiDiagnosticMode
      });
      
      // ç›´æ¥é–‹å§‹è½‰éŒ„æµç¨‹ï¼Œä¸é€²è¡Œé¡å¤–çš„é€£æ¥æ¸¬è©¦
      
      const segments = createAudioSegments(audioBlob, originalChunks, durationSeconds);
      console.log('ğŸ“¼ åˆ†æ®µè³‡è¨Š:', segments.map(s => ({ index: s.index + 1, duration: s.duration }))); 

      const mimeType = audioBlob.type || 'audio/webm';
      const transcriptSegments: string[] = [];
      const totalSecondsForDirect = segments.reduce((sum, s) => sum + (s.duration || (s.end - s.start) || 0), 0);
      progressEstRef.current[jobId] = { startTs: Date.now(), totalSeconds: Math.max(totalSecondsForDirect, 1), processedSeconds: 0, lastEmitTs: 0 };

      updateJob(jobId, { status: 'stt', progress: 5 });
      setRecordingStatus(`API é€£æ¥æˆåŠŸï¼Œæº–å‚™è™•ç†éŸ³è¨Šï¼ˆå…± ${segments.length} æ®µï¼‰...`);

      for (const segment of segments) {
        const partLabel = segments.length > 1
          ? `ç¬¬ ${segment.index + 1}/${segments.length} æ®µï¼ˆç´„ ${Math.round(segment.start)}s ~ ${Math.round(segment.end)}sï¼‰`
          : 'æ•´æ®µéŸ³è¨Š';

        setRecordingStatus(`æ­£åœ¨ä¸Šå‚³ ${partLabel} åˆ° Gemini...`);
        const segmentFilename = segments.length > 1
          ? `${filename.replace(/\.\w+$/, '')}-part-${segment.index + 1}.webm`
          : filename;

        const uploadResult = await geminiClient.uploadFile(segment.blob, segmentFilename);
        console.log(`Gemini æ®µè½ä¸Šå‚³å®Œæˆ (${segment.index + 1}/${segments.length}):`, uploadResult.name);

        const estD = progressEstRef.current[jobId];
        if (estD) {
          const d = segment.duration || (segment.end - segment.start) || 0;
          estD.processedSeconds = Math.min(estD.totalSeconds, estD.processedSeconds + Math.max(d, 0));
          safeUpdateJobProgress(jobId, estD.processedSeconds, estD.totalSeconds, 'èªéŸ³è½‰æ–‡å­—è™•ç†ä¸­');
        }

        await new Promise(resolve => setTimeout(resolve, 1500));

        setRecordingStatus(`é–‹å§‹è½‰éŒ„ ${partLabel}...`);
        const transcriptionResult = await geminiClient.generateTranscription(
          uploadResult.uri,
          mimeType,
          settings.customTranscriptPrompt,
          settings.vocabularyList,
          {
            index: segment.index,
            total: segments.length,
            startTime: segment.start,
            endTime: segment.end
          }
        );

        transcriptSegments.push(transcriptionResult.trim());

        const segmentProgress = 30 + Math.floor(((segment.index + 1) / segments.length) * 30);
        updateJob(jobId, { progress: segmentProgress });
        await new Promise(resolve => setTimeout(resolve, 1200));
      }

      const combinedTranscriptRaw = transcriptSegments.join('\n\n');
      console.log('Gemini é€å­—ç¨¿åˆä½µå®Œæˆ');

      const cleanedTranscript = await cleanupTranscriptInChunks(
        geminiClient,
        combinedTranscriptRaw,
        settings.customTranscriptCleanupPrompt
      );

      const parsedResult = geminiClient.parseTranscriptionResult(cleanedTranscript);
      // é€å­—ç¨¿ä¸€å¾‹ç°¡è½‰ç¹ï¼ˆå°ç£ï¼‰
      try {
        const { toTW } = await import('./utils/zhConvert');
        parsedResult.transcript.fullText = await toTW(parsedResult.transcript.fullText);
      } catch {}
      const estAfter = progressEstRef.current[jobId];
      if (estAfter) safeUpdateJobProgress(jobId, Math.max(estAfter.processedSeconds, estAfter.totalSeconds * 0.9), estAfter.totalSeconds, 'é€å­—ç¨¿ä¿®æ­£ä¸­');
      const geminiSegments = mergeSegmentsWithCleanTranscript(
        Array.isArray(parsedResult.transcript?.segments)
          ? (parsedResult.transcript.segments as TranscriptSegment[])
          : [],
        parsedResult.transcript.fullText
      );
      
      // 4. å¾Œè™•ç†ï¼šæ‡‰ç”¨è©å½™è¡¨ä¿®æ­£ï¼ˆé›™é‡ä¿éšªï¼‰
      if (settings.vocabularyList && settings.vocabularyList.length > 0) {
        parsedResult.transcript.fullText = VocabularyService.applyVocabularyCorrections(
          parsedResult.transcript.fullText, 
          settings.vocabularyList
        );
        console.log('è©å½™è¡¨å¾Œè™•ç†å®Œæˆ');
      }
      
      // 5. ç¬¬äºŒæ­¥ï¼šç”Ÿæˆè‡ªè¨‚æœƒè­°ç¸½çµï¼ˆå¦‚æœæœ‰è‡ªè¨‚æ‘˜è¦æç¤ºè©ï¼‰
      let finalSummary = parsedResult.summary;
      // è‹¥å­˜åœ¨é è¨­æ‘˜è¦ï¼Œå…ˆåšç°¡è½‰ç¹è™•ç†ï¼ˆminutesMd èˆ‡ overallSummaryï¼‰
      try {
        const { toTW } = await import('./utils/zhConvert');
        if (finalSummary?.minutesMd) finalSummary.minutesMd = await toTW(finalSummary.minutesMd);
        if (finalSummary?.overallSummary) finalSummary.overallSummary = await toTW(finalSummary.overallSummary);
      } catch {}
      if (settings.customSummaryPrompt) {
        setRecordingStatus('é€å­—ç¨¿å®Œæˆï¼Œç­‰å¾…å¾Œå†ç”Ÿæˆè‡ªè¨‚æ‘˜è¦...');
        
        // æ·»åŠ å»¶é²ä»¥é¿å…è«‹æ±‚éæ–¼é »ç¹
        await new Promise(resolve => setTimeout(resolve, 3000));
        setRecordingStatus('é–‹å§‹ç”Ÿæˆè‡ªè¨‚æ‘˜è¦...');
        
        try {
          let customSummaryResult = await geminiClient.generateCustomSummary(
            parsedResult.transcript.fullText,
            settings.customSummaryPrompt
          );
          // è‡ªè¨‚æ‘˜è¦ä¹Ÿè½‰ç¹
          try {
            const { toTW } = await import('./utils/zhConvert');
            customSummaryResult = await toTW(customSummaryResult);
          } catch {}
          console.log('Gemini è‡ªè¨‚æ‘˜è¦å®Œæˆ:', customSummaryResult);
          
          // ç”¨è‡ªè¨‚æ‘˜è¦æ›¿æ›åŸä¾†çš„æ‘˜è¦
          finalSummary = {
            ...parsedResult.summary,
            overallSummary: customSummaryResult,
            minutesMd: `# è‡ªè¨‚æœƒè­°æ‘˜è¦\n\n${customSummaryResult}`
          };
        } catch (summaryError) {
          console.error('è‡ªè¨‚æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­æ‘˜è¦:', summaryError);
          // å¦‚æœè‡ªè¨‚æ‘˜è¦å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨åŸä¾†çš„æ‘˜è¦
        }
      }
      // 6. æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºå®Œæˆï¼ˆé€å­—ç¨¿æ®µè½è½‰ç¹ï¼‰
      let twSegments = geminiSegments;
      try {
        const { toTW } = await import('./utils/zhConvert');
        twSegments = await Promise.all(
          geminiSegments.map(async (seg) => ({ ...seg, text: await toTW(seg.text || '') }))
        );
      } catch {}
      updateJob(jobId, { status: 'done', transcript: parsedResult.transcript.fullText, transcriptSegments: twSegments, summary: finalSummary.minutesMd });
      if (estAfter) safeUpdateJobProgress(jobId, estAfter.totalSeconds, estAfter.totalSeconds, 'å®Œæˆ');
      
      setRecordingStatus('Gemini è½‰éŒ„å®Œæˆï¼å¯åœ¨çµæœé æŸ¥çœ‹è©³ç´°å…§å®¹');
      
    } catch (error) {
      console.error('Gemini è½‰éŒ„å¤±æ•—:', error);

      // æ”¹é€²éŒ¯èª¤è¨Šæ¯ï¼Œæä¾›æ›´å…·é«”çš„æŒ‡å°
      let errorMessage = '';
      let suggestions: string[] = [];

      if (error instanceof Error) {
        const errorMsg = error.message;

        if (errorMsg.includes('503')) {
          errorMessage = 'Gemini API æœå‹™ç›®å‰éè¼‰';
          suggestions = [
            'è«‹ç¨ç­‰ 5-10 åˆ†é˜å¾Œé‡è©¦',
            'å˜—è©¦åœ¨éé«˜å³°æ™‚æ®µä½¿ç”¨',
            'æª¢æŸ¥ Google API æœå‹™ç‹€æ…‹'
          ];
        } else if (errorMsg.includes('429')) {
          errorMessage = 'API ä½¿ç”¨é…é¡å·²é”ä¸Šé™';
          suggestions = [
            'ç­‰å¾…é…é¡é‡ç½®ï¼ˆé€šå¸¸ç‚ºæ¯æ—¥é‡ç½®ï¼‰',
            'å‡ç´šæ‚¨çš„ Google Cloud æ–¹æ¡ˆ',
            'æª¢æŸ¥ API é…é¡è¨­å®š'
          ];
        } else if (errorMsg.includes('401') || errorMsg.includes('Invalid API key')) {
          errorMessage = 'API é‡‘é‘°ç„¡æ•ˆæˆ–å·²éæœŸ';
          suggestions = [
            'æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦æ­£ç¢º',
            'ç¢ºèª API é‡‘é‘°æ¬Šé™è¨­å®š',
            'é‡æ–°ç”Ÿæˆ API é‡‘é‘°'
          ];
        } else if (errorMsg.includes('403')) {
          errorMessage = 'API æ¬Šé™ä¸è¶³';
          suggestions = [
            'ç¢ºèªå·²å•Ÿç”¨ Generative Language API',
            'æª¢æŸ¥ API é‡‘é‘°æ¬Šé™è¨­å®š',
            'è¯ç¹«ç®¡ç†å“¡ç¢ºèªæ¬Šé™'
          ];
        } else if (errorMsg.includes('Failed to fetch') || errorMsg.includes('Network')) {
          errorMessage = 'ç¶²è·¯é€£æ¥å•é¡Œ';
          suggestions = [
            'æª¢æŸ¥ç¶²è·¯é€£æ¥',
            'ç¢ºèªé˜²ç«ç‰†è¨­å®š',
            'å˜—è©¦é‡æ–°é€£æ¥ç¶²è·¯'
          ];
      } else {
        errorMessage = errorMsg;
        if (/INVALID_ARGUMENT/i.test(errorMsg)) {
          suggestions = [
            'ç¢ºèªæœªåœ¨é chirp_3 æ¨¡å‹å•Ÿç”¨èªªè©±è€…åˆ†æ®µï¼ˆDiarizationï¼‰',
            'è‹¥éœ€ Diarizationï¼Œè«‹å°‡æ¨¡å‹è¨­ç‚º chirp_3 ä¸¦ä½¿ç”¨èªè¨€ cmn-Hans-CN',
            'æˆ–å…ˆé—œé–‰ Diarization åƒ…ä¿ç•™å­—è©æ™‚é–“æˆ³ï¼ˆWord Offsetsï¼‰',
          ];
        } else {
          suggestions = [
            'æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œ API è¨­å®š',
            'æŸ¥çœ‹è©³ç´°éŒ¯èª¤æ—¥èªŒ',
            'å˜—è©¦é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼'
          ];
        }
      }
      } else {
        errorMessage = 'æœªçŸ¥éŒ¯èª¤';
        suggestions = ['è«‹é‡è©¦æˆ–è¯ç¹«æŠ€è¡“æ”¯æ´'];
      }

      const fullMessage = `âŒ ${errorMessage}\n\nğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆ:\n${suggestions.map(s => `â€¢ ${s}`).join('\n')}`;
      updateJob(jobId, {
        status: 'failed',
        errorMessage,
        progressMessage: fullMessage
      });
      setRecordingStatus(fullMessage);

      // è¨˜éŒ„éŒ¯èª¤åˆ°æ§åˆ¶å°ï¼Œä¾¿æ–¼èª¿è©¦
      const { settings: debugSettings } = useSettingsStore.getState();
      console.error('ğŸ” Gemini è½‰éŒ„è©³ç´°éŒ¯èª¤è³‡è¨Š:', {
        error: error instanceof Error ? error.message : error,
        stack: error instanceof Error ? error.stack : undefined,
        settings: {
          hasApiKey: !!getGeminiKey(debugSettings),
          preferredModel: debugSettings.geminiPreferredModel,
          enableFallback: debugSettings.geminiEnableFallback,
          retryConfig: debugSettings.geminiRetryConfig
        }
      });
    }
  };

  // ä½¿ç”¨åŸæœ‰ API é€²è¡Œè½‰éŒ„
  const startOriginalApiTranscription = async (audioBlob: Blob, filename: string, jobId: string, originalChunks: Blob[] = [], durationSeconds: number = recordingTime) => {
    try {
      const api = getAPI();
      
      // 1. å‰µå»ºæœƒè­°
      const meetingResponse = await api.createMeeting({
        title: `éŒ„éŸ³è½‰éŒ„ - ${filename}`,
        participants: [],
        options: {
          language: 'zh-TW'
        }
      });
      
      console.log('æœƒè­°å‰µå»ºæˆåŠŸ:', meetingResponse);
      
      // 2. ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ
      const audioFile = new File([audioBlob], filename, { type: 'audio/webm' });
      await api.uploadAudio(meetingResponse.id, audioFile);
      console.log('éŸ³è¨Šæª”æ¡ˆä¸Šå‚³æˆåŠŸ');
      
      // 3. å®Œæˆæœƒè­°ï¼Œé–‹å§‹è™•ç†
      await api.completeMeeting(meetingResponse.id);
      console.log('æœƒè­°æ¨™è¨˜ç‚ºå®Œæˆï¼Œé–‹å§‹è½‰éŒ„è™•ç†');
      
      // 4. é–‹å§‹è¼ªè©¢ç‹€æ…‹
      startStatusPolling(meetingResponse.id, jobId);
      
    } catch (error) {
      console.error('åŸæœ‰ API è½‰éŒ„å¤±æ•—:', error);
      updateJob(jobId, { status: 'failed' });
      setRecordingStatus('API è½‰éŒ„å¤±æ•—: ' + (error as Error).message);
    }
  };


  // è™•ç†æª”æ¡ˆä¸Šå‚³
  const handleFileUpload = async (file: File) => {
    try {
      console.log('é–‹å§‹è™•ç†ä¸Šå‚³æª”æ¡ˆ:', file.name, file.type, file.size);
      
      const validation = validateMediaFile(file);
      if (!validation.isValid) {
        const message = Object.values(validation.errors).join('\n');
        alert(message || 'æª”æ¡ˆé©—è­‰å¤±æ•—ï¼Œè«‹é‡æ–°é¸æ“‡æª”æ¡ˆã€‚');
        setRecordingStatus(message || 'åª’é«”æª”æ¡ˆé©—è­‰å¤±æ•—');
        return;
      }

      setRecordingStatus(`æ­£åœ¨è™•ç†æª”æ¡ˆ: ${file.name}...`);
      
      // å°‡ File è½‰æ›ç‚º Blob
      const normalizedType = normalizeMimeType(file.type) || inferMimeFromExtension(file.name) || file.type || 'audio/m4a';
      const fileBlob = new Blob([file], { type: normalizedType });
      const estimatedDuration = await getBlobDuration(fileBlob).catch(() => 0);
      
      // ç›´æ¥å•Ÿå‹•è½‰éŒ„æµç¨‹
      await startTranscriptionJob(fileBlob, file.name, [], estimatedDuration || recordingTime);
      
    } catch (error) {
      console.error('æª”æ¡ˆä¸Šå‚³è™•ç†å¤±æ•—:', error);
      setRecordingStatus('æª”æ¡ˆè™•ç†å¤±æ•—: ' + (error as Error).message);
      alert('æª”æ¡ˆè™•ç†å¤±æ•—: ' + (error as Error).message);
    }
  };

  // ç‹€æ…‹è¼ªè©¢
  const startStatusPolling = async (meetingId: string, jobId: string) => {
    try {
      const api = getAPI();
      
      await api.pollMeetingStatus(
        meetingId,
        (status) => {
          console.log('ç‹€æ…‹æ›´æ–°:', status);
          
          const progressMessage = JOB_STATUS_HINTS[status.status] || recordingStatus;
          const progressValue = status.progress ?? 0;

          // æ›´æ–°ä½œæ¥­ç‹€æ…‹
          updateJob(jobId, {
            status: status.status,
            progress: progressValue,
            progressMessage
          });
          
          // æ›´æ–°éŒ„éŸ³ç‹€æ…‹é¡¯ç¤º
          setRecordingStatus(progressMessage);
        },
        2000, // æ¯2ç§’è¼ªè©¢ä¸€æ¬¡
        150   // æœ€å¤š5åˆ†é˜
      );
      
      // è™•ç†å®Œæˆå¾Œç²å–çµæœ
      const result = await api.getMeetingResult(meetingId);
      console.log('è½‰éŒ„çµæœ:', result);
      
      // æ›´æ–°ä½œæ¥­çµæœï¼ˆçµ±ä¸€è½‰ç‚ºç¹é«”ï¼‰
      let minutesMd = result.summary?.minutesMd || '';
      let transcriptText = result.transcript?.segments?.map(s => s.text).join('\n') || '';
      let transcriptSegments = result.transcript?.segments || [];
      try {
        const { toTW } = await import('./utils/zhConvert');
        minutesMd = await toTW(minutesMd);
        transcriptText = await toTW(transcriptText);
        transcriptSegments = await Promise.all(
          (transcriptSegments || []).map(async (s: any) => ({ ...s, text: await toTW(s.text || '') }))
        );
      } catch {}

      updateJob(jobId, {
        transcript: transcriptText,
        transcriptSegments,
        summary: minutesMd,
        status: 'done',
        progress: 100,
        progressMessage: JOB_STATUS_HINTS.done
      });
      
      setRecordingStatus('è½‰éŒ„å®Œæˆï¼å¯åœ¨çµæœé æŸ¥çœ‹è©³ç´°å…§å®¹');
      
    } catch (error) {
      console.error('ç‹€æ…‹è¼ªè©¢å¤±æ•—:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      updateJob(jobId, {
        status: 'failed',
        errorMessage,
        progressMessage: `${JOB_STATUS_HINTS.failed}ï¼š${errorMessage}`
      });
      setRecordingStatus('è½‰éŒ„è™•ç†å¤±æ•—: ' + errorMessage);
    }
  };

  const renderCurrentPage = () => {
    switch (currentPage) {
      case 'record': {
        const permissionState = hasAudioPermission === false ? 'danger' : hasAudioPermission === true ? 'success' : 'warning';

        const latestJob = jobs[0];
        const activeJob = jobs.find(job => job.status !== 'done' && job.status !== 'failed');
        const failedJob = latestJob && latestJob.status === 'failed' ? latestJob : null;
        const completedJob = latestJob && latestJob.status === 'done' ? latestJob : null;

        let bannerVariant: 'success' | 'warning' | 'danger' | 'info' = permissionState;
        let bannerIcon: React.ReactNode = permissionState === 'danger'
          ? <Icon name="warning" />
          : hasAudioPermission === true
            ? <Icon name="success" />
            : <Icon name="info" />;
        let bannerTitle = permissionState === 'danger' ? 'æ¬Šé™å•é¡Œ' : hasAudioPermission === true ? 'è£ç½®æº–å‚™å°±ç·’' : 'æ¬Šé™æª¢æŸ¥ä¸­';
        let bannerDesc = recordingStatus;
        let bannerProgress: number | null = null;

        if (hasAudioPermission === false) {
          bannerVariant = 'danger';
          bannerIcon = <Icon name="warning" />;
          bannerTitle = 'éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•';
          bannerDesc = 'è«‹å‰å¾€ç³»çµ±è¨­å®š > éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ > éº¥å…‹é¢¨ï¼Œå…è¨±æ­¤æ‡‰ç”¨ä½¿ç”¨éº¥å…‹é¢¨ã€‚';
        } else if (activeJob) {
          bannerVariant = 'info';
          bannerIcon = <Icon name="info" />;
          bannerTitle = `æ­£åœ¨è™•ç†ï¼š${activeJob.filename}`;
          const hint = activeJob.progressMessage || JOB_STATUS_HINTS[activeJob.status] || 'ä»»å‹™è™•ç†ä¸­';
          bannerDesc = hint;
          const progressValue = activeJob.progress ?? 0;
          bannerProgress = Math.max(8, Math.min(100, progressValue));
        } else if (failedJob) {
          bannerVariant = 'danger';
          bannerIcon = <Icon name="error" />;
          bannerTitle = `è™•ç†å¤±æ•—ï¼š${failedJob.filename}`;
          const message = failedJob.progressMessage || failedJob.errorMessage || JOB_STATUS_HINTS.failed;
          bannerDesc = message;
        } else if (completedJob) {
          bannerVariant = 'success';
          bannerIcon = <Icon name="success" />;
          bannerTitle = `è½‰éŒ„å®Œæˆï¼š${completedJob.filename}`;
          bannerDesc = completedJob.progressMessage || JOB_STATUS_HINTS.done;
        } else if (hasAudioPermission === null) {
          bannerVariant = 'warning';
          bannerIcon = <Icon name="info" />;
          bannerTitle = 'æ¬Šé™æª¢æŸ¥ä¸­';
          bannerDesc = 'æ­£åœ¨æª¢æŸ¥éº¥å…‹é¢¨æ¬Šé™...';
        } else {
          bannerVariant = 'success';
          bannerIcon = <Icon name="success" />;
          bannerTitle = 'è£ç½®æº–å‚™å°±ç·’';
          bannerDesc = recordingStatus || 'å·²ç²å¾—éº¥å…‹é¢¨æ¬Šé™ï¼Œæº–å‚™å°±ç·’';
        }

        const recordModes: Array<{ id: typeof recordingMode; title: string; description: string }> = [
          { id: 'both', title: 'æ··åˆæ¨¡å¼ (æ¨è–¦)', description: 'åŒæ™‚éŒ„è£½ç³»çµ±éŸ³è¨Šèˆ‡éº¥å…‹é¢¨ï¼Œé©åˆç·šä¸Šæœƒè­°' },
          { id: 'system', title: 'ç³»çµ±è²éŸ³', description: 'åƒ…æ“·å–ç³»çµ±æ’­æ”¾çš„è²éŸ³ï¼Œé©åˆç·šä¸Šæœƒè­°' },
          { id: 'microphone', title: 'éº¥å…‹é¢¨', description: 'åƒ…æ“·å–éº¥å…‹é¢¨è¼¸å…¥ï¼Œé©åˆè¨ªè«‡æˆ–ç¾å ´è¨˜éŒ„' }
        ];

        const currentTask = jobs[0];
        const completedJobs = jobs.filter(job => job.status === 'done').slice(0, 2);

        const timelineSteps: Array<{ key: MeetingStatus; label: string }> = [
          { key: 'queued', label: 'æ’éšŠ' },
          { key: 'stt', label: 'èªéŸ³è½‰æ–‡å­—' },
          { key: 'summarize', label: 'æ‘˜è¦ç”Ÿæˆ' },
          { key: 'done', label: 'å®Œæˆ' }
        ];

        const renderRecordingSession = () => (
          <div className="recording-session">
            <div className="recording-session__badge">
              <span className="recording-session__dot" />
              <span>éŒ„éŸ³é€²è¡Œä¸­</span>
            </div>
            <div className="recording-session__time">{formatTime(recordingTime)}</div>
            <div className="recording-session__buttons">
              <button onClick={stopRecording} className="btn btn--surface btn--xl">åœæ­¢éŒ„éŸ³</button>
              <button onClick={cancelRecording} className="btn btn--danger btn--xl">å–æ¶ˆéŒ„éŸ³</button>
            </div>
            <p className="recording-session__hint">å–æ¶ˆå¾Œæœ¬æ®µéŒ„éŸ³ä¸æœƒä¿å­˜æˆ–é€²è¡Œè½‰éŒ„ã€‚</p>
          </div>
        );

        const handleRetryJob = async (job: typeof jobs[number]) => {
          // 1) è‹¥æœ¬æ©Ÿæš«å­˜éŒ„éŸ³å­˜åœ¨æ–¼è¨˜æ†¶åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
          const draft = recordings.find(r => r.filename === job.filename);
          if (draft) {
            startTranscriptionJob(draft.blob, draft.filename, draft.chunks || [], draft.duration, { sourcePath: draft.filePath });
            return;
          }

          // 2) å˜—è©¦ç”¨ä½œæ¥­è¨˜éŒ„ä¸­çš„ audioFile é‡æ–°è®€å–
          if (job.audioFile) {
            try {
              const existsRes = await window.electronAPI.recording.fileExists(job.audioFile);
              if (existsRes?.success && existsRes.exists) {
                const readRes = await window.electronAPI.recording.readFile(job.audioFile);
                if (readRes?.success && readRes.buffer) {
                  const extMime = inferMimeFromExtension(job.filename) || inferMimeFromExtension(job.audioFile) || 'audio/wav';
                  const blob = new Blob([readRes.buffer], { type: extMime });
                  const duration = await getBlobDuration(blob).catch(() => 0);
                  startTranscriptionJob(blob, job.filename, [], duration || recordingTime, { sourcePath: job.audioFile });
                  return;
                }
              }
            } catch {}
          }

          // 3) æ‰¾ä¸åˆ°æˆ–å·²è¢«æ¸…ç†ï¼šè«‹ä½¿ç”¨è€…æ‰‹å‹•é¸æ“‡åŸå§‹æª”æ¡ˆ
          const pick = await (window.electronAPI as any)?.dialog?.openFile?.();
          if (pick && !pick.canceled && pick.filePath) {
            try {
              const readRes = await window.electronAPI.recording.readFile(pick.filePath);
              if (readRes?.success && readRes.buffer) {
                const chosenName = pick.filePath.split(/[\\/]/).pop() || job.filename;
                const extMime = inferMimeFromExtension(chosenName) || 'audio/wav';
                const blob = new Blob([readRes.buffer], { type: extMime });
                const duration = await getBlobDuration(blob).catch(() => 0);
                startTranscriptionJob(blob, chosenName, [], duration || recordingTime, { sourcePath: pick.filePath });
                return;
              }
            } catch (e) {
              console.error('è®€å–æ‰‹å‹•é¸æ“‡çš„æª”æ¡ˆå¤±æ•—:', e);
            }
          }

          alert('æ‰¾ä¸åˆ°åŸå§‹éŒ„éŸ³æª”æ¡ˆï¼Œè«‹é‡æ–°éŒ„è£½æˆ–ä¸Šå‚³ã€‚');
        };

        return (
          <div className="record-dashboard">
            <div className={`status-bar status-bar--${bannerVariant}`}>
              <div className="status-bar__icon">{bannerIcon}</div>
              <div className="status-bar__content">
                <h1 className="status-bar__title">{bannerTitle}</h1>
                <p className="status-bar__subtitle">{bannerDesc}</p>
                {bannerProgress !== null && (
                  <div className="status-progress">
                    <div className="status-progress__bar" style={{ width: `${bannerProgress}%` }} />
                  </div>
                )}
              </div>
            </div>

            <div className="record-dashboard__grid">
              <section className="quick-panel">
                <header className="quick-panel__header">
                  <div>
                    <h2>å¿«é€Ÿé–‹å§‹éŒ„éŸ³</h2>
                    <p>é¸æ“‡æ”¶éŸ³æ¨¡å¼ä¸¦å•Ÿå‹•æ™ºæ…§è½‰éŒ„æµç¨‹ã€‚</p>
                  </div>
                  {hasAudioPermission !== true && (
                    <button className="btn btn--minimal" onClick={testAudioAccess}>é‡æ–°æª¢æŸ¥éº¥å…‹é¢¨</button>
                  )}
                </header>

                {isRecording ? (
                  renderRecordingSession()
                ) : (
                  <div className="quick-panel__cta">
                    <button
                      className="btn btn--primary btn--xl"
                      onClick={startRecording}
                      disabled={hasAudioPermission === false}
                    >
                      é–‹å§‹æœƒè­°éŒ„éŸ³
                      </button>

                    <label className="upload-tile">
                      <div className="upload-tile__icon"><Icon name="upload" /></div>
                      <div>
                        <div className="upload-tile__title">ä¸Šå‚³éŸ³è¨Šæˆ–å½±ç‰‡</div>
                        <div className="upload-tile__hint">æ‹–æ”¾æˆ–é»æ“Šé¸æ“‡ï¼Œæ”¯æ´ MP3ã€WAVã€MP4 ç­‰æ ¼å¼</div>
                      </div>
                      <input
                        type="file"
                        accept="audio/*,video/*"
                        onChange={(e) => {
                          const file = e.target.files?.[0];
                          if (file) {
                            handleFileUpload(file);
                            e.target.value = '';
                          }
                        }}
                      />
                    </label>
                  </div>
                )}

                <div className="mode-selector">
                  {recordModes.map(option => (
                    <button
                      key={option.id}
                      className={`mode-selector__pill ${recordingMode === option.id ? 'is-active' : ''}`}
                      onClick={() => setRecordingMode(option.id)}
                      type="button"
                    >
                      <span className="mode-selector__title">{option.title}</span>
                      <span className="mode-selector__desc">{option.description}</span>
                    </button>
                  ))}
                </div>

                <div className="mode-selector__hint">
                  {recordingMode === 'both' && 'æ··åˆæ¨¡å¼éœ€æˆæ¬Šè¢å¹•åˆ†äº«èˆ‡éº¥å…‹é¢¨æ¬Šé™ã€‚'}
                  {recordingMode === 'system' && 'ç³»çµ±è²éŸ³æ¨¡å¼éœ€æˆæ¬Šè¢å¹•åˆ†äº«æ¬Šé™ã€‚'}
                  {recordingMode === 'microphone' && 'éº¥å…‹é¢¨æ¨¡å¼åƒ…éœ€æˆæ¬Šéº¥å…‹é¢¨æ¬Šé™ã€‚'}
                </div>

                {/* å¤§å‹æ‹–æ”¾å€ï¼šå¡«è£œå·¦å´ç©ºç™½ä¸¦æä¾›ç›´è¦ºä¸Šå‚³ */}
                <div
                  className="quick-panel__dropzone"
                  onDragOver={(e) => {
                    e.preventDefault();
                    (e.currentTarget as HTMLDivElement).classList.add('is-dragover');
                  }}
                  onDragLeave={(e) => {
                    (e.currentTarget as HTMLDivElement).classList.remove('is-dragover');
                  }}
                  onDrop={(e) => {
                    e.preventDefault();
                    (e.currentTarget as HTMLDivElement).classList.remove('is-dragover');
                    const file = e.dataTransfer?.files?.[0];
                    if (file) {
                      handleFileUpload(file);
                    }
                  }}
                >
                  å°‡éŸ³è¨Šæˆ–å½±ç‰‡æ‹–æ”¾åˆ°æ­¤è™•å³å¯ä¸Šå‚³ï¼ˆæ”¯æ´ MP3 Â· WAV Â· MP4 ç­‰ï¼‰
                </div>

                <footer className="quick-panel__footer">
                  <div className="quick-panel__stat">
                    <span>éŒ„éŸ³å„²å­˜è·¯å¾‘</span>
                    <div className="quick-panel__row">
                      <strong className="quick-panel__path" title={settings.recordingSavePath || ''}>{settings.recordingSavePath || 'é è¨­ä¸‹è¼‰è³‡æ–™å¤¾'}</strong>
                      <button className="btn btn--surface" onClick={handleChooseSavePath}>é¸æ“‡â€¦</button>
                    </div>
                  </div>
                  <div className="quick-panel__stat">
                    <span>API ç‹€æ…‹</span>
                    <span className={`chip chip--${getGeminiKey(settings) ? 'success' : 'danger'}`}>
                      {getGeminiKey(settings) ? 'Gemini é‡‘é‘°å·²è¨­å®š' : 'å°šæœªè¨­å®šé‡‘é‘°'}
                    </span>
                  </div>
                </footer>

                {recordings.length > 0 && (
                  <div className="draft-list">
                    <div className="draft-list__header">
                      <h3>è‰ç¨¿éŒ„éŸ³</h3>
                      <span className="chip chip--neutral">{recordings.length} ç­†</span>
                    </div>
                    <div className="draft-list__body">
                      {recordings.map(recording => (
                        <div key={recording.id} className="draft-item">
                          <div>
                          <div className="draft-item__name" title={recording.filename}>{require('./utils/filename').getDisplayName(recording.filename, 'medium')}</div>
                            <div className="draft-item__meta">{recording.timestamp} Â· {formatTime(recording.duration)} Â· {(recording.size / 1024).toFixed(1)} KB</div>
                          </div>
                          <div className="draft-item__actions">
                            <button
                              className="btn btn--primary"
                              onClick={() => startTranscriptionJob(
                                recording.blob,
                                recording.filename,
                                recording.chunks || [],
                                recording.duration,
                                { sourcePath: recording.filePath }
                              )}
                            >
                              ğŸ¯ é–‹å§‹è½‰éŒ„
                            </button>
                            <button className="btn btn--minimal" onClick={() => downloadRecording(recording)}>ä¸‹è¼‰</button>
                          </div>
                        </div>
                      ))}
                    </div>
                  </div>
                )}
              </section>

              <section className="task-panel">
                <div className="task-panel__card">
                  <div className="task-panel__header">
                    <div>
                      <h3>ç›®å‰ä»»å‹™ç‹€æ…‹</h3>
                      <p>å³æ™‚æŒæ¡è½‰éŒ„æµç¨‹èˆ‡æ‘˜è¦ç”¢å‡ºé€²åº¦ã€‚</p>
                    </div>
                    {currentTask && (
                      <span className={`chip chip--${currentTask.status === 'done' ? 'success' : currentTask.status === 'failed' ? 'danger' : 'warning'}`}>
                        {currentTask.status === 'done' ? 'å·²å®Œæˆ' : currentTask.status === 'failed' ? 'å¤±æ•—' : 'é€²è¡Œä¸­'}
                      </span>
                    )}
                  </div>

                  {currentTask ? (
                    <>
                      <div className="task-panel__file">
                        <div className="task-panel__file-icon"><Icon name="file" /></div>
                        <div>
                          <div className="task-panel__file-name" title={currentTask.filename}>{require('./utils/filename').getDisplayName(currentTask.filename, 'medium')}</div>
                          <div className="task-panel__file-meta">å»ºç«‹æ™‚é–“ï¼š{currentTask.createdAt}</div>
                        </div>
                      </div>

                      <div className="timeline">
                        {timelineSteps.map(step => {
                          const currentIndex = timelineSteps.findIndex(s => s.key === currentTask.status);
                          const stepIndex = timelineSteps.findIndex(s => s.key === step.key);
                          const isCompleted = currentTask.status === 'done' || stepIndex < currentIndex;
                          const isActive = step.key === currentTask.status;
                          return (
                            <div key={step.key} className={`timeline__step ${isCompleted ? 'is-completed' : ''} ${isActive ? 'is-active' : ''}`}>
                              <div className="timeline__dot" />
                              <span className="timeline__label">{step.label}</span>
                            </div>
                          );
                        })}
                      </div>

                      {currentTask.progressMessage && (
                        <div className="task-panel__message">{currentTask.progressMessage}</div>
                      )}

                      <div className="task-panel__actions">
                        {currentTask.status === 'done' && (
                          <button className="btn btn--primary" onClick={() => setCurrentPage('result')}>æŸ¥çœ‹çµæœ</button>
                        )}
                        {currentTask.status === 'failed' && (
                          <button className="btn btn--surface" onClick={() => handleRetryJob(currentTask)}>ğŸ” é‡æ–°å˜—è©¦</button>
                        )}
                      </div>
                    </>
                  ) : (
                    <div className="task-panel__empty">
                      <div className="task-panel__empty-icon"><Icon name="clock" /></div>
                      <div className="task-panel__empty-title">å°šç„¡é€²è¡Œä¸­çš„ä»»å‹™</div>
                      <div className="task-panel__empty-text">é–‹å§‹éŒ„éŸ³æˆ–ä¸Šå‚³æª”æ¡ˆå¾Œï¼Œè½‰éŒ„é€²åº¦æœƒé¡¯ç¤ºåœ¨é€™è£¡ã€‚</div>
                    </div>
                  )}
                </div>

                <div className="recent-panel">
                  <div className="recent-panel__header">
                    <h4>æœ€è¿‘å®Œæˆ</h4>
                    <button className="btn btn--minimal" onClick={() => setCurrentPage('result')}>æª¢è¦–å…¨éƒ¨</button>
                  </div>
                  {completedJobs.length === 0 ? (
                    <p className="recent-panel__empty">å°šæœªæœ‰å®Œæˆçš„è½‰éŒ„çµæœã€‚</p>
                  ) : (
                    <ul className="recent-panel__list">
                      {completedJobs.map(job => (
                        <li key={job.id}>
                          <div>
                            <div className="recent-panel__name" title={job.filename}>{require('./utils/filename').getDisplayName(job.filename, 'medium')}</div>
                            <div className="recent-panel__time">å®Œæˆæ™‚é–“ï¼š{job.createdAt}</div>
                          </div>
                          <button className="btn btn--surface" onClick={() => setCurrentPage('result')}>æŸ¥çœ‹çµæœ</button>
                        </li>
                      ))}
                    </ul>
                  )}
                </div>
              </section>
            </div>
          </div>
        );
      }
      case 'result': {
        const completedJobs = jobs.filter(job => job.status === 'done' && (job.transcript || job.summary));

        if (completedJobs.length === 0) {
          return (
            <div className="page-scroll">
              <div className="jobs-empty" style={{ marginTop: '2rem' }}>
                <div className="empty-state__icon"><Icon name="file" /></div>
                <h3 className="empty-state__title">æš«ç„¡å®Œæˆçš„è½‰éŒ„çµæœ</h3>
                <p className="empty-state__text">å®Œæˆè½‰éŒ„å¾Œçµæœå°‡æœƒé¡¯ç¤ºåœ¨é€™è£¡</p>
              </div>
            </div>
          );
        }

        const safeIndex = Math.min(currentJobIndex, completedJobs.length - 1);
        const currentJob = completedJobs[safeIndex];
        // åˆ†é è¨­å®š
        const pageSize = 12;
        const totalPages = Math.max(1, Math.ceil(completedJobs.length / pageSize));
        const currentPage = Math.min(Math.max(resultsPage, 1), totalPages);
        const start = (currentPage - 1) * pageSize;
        const end = start + pageSize;
        const pagedJobs = completedJobs.slice(start, end);

        const buildExportContent = (job: typeof currentJob) => {
          const summarySection = job.summary ? `æœƒè­°æ‘˜è¦ï¼š
${job.summary}

` : '';
          const transcriptSection = job.transcript ? `å®Œæ•´è½‰éŒ„ï¼š
${job.transcript}` : '';
          return `æª”æ¡ˆï¼š${job.filename}
å®Œæˆæ™‚é–“ï¼š${job.createdAt}

${summarySection}${transcriptSection}`;
        };

        const getResultSnippet = (job: typeof currentJob) => {
          const sourceText = job.summary || job.transcript;
          if (!sourceText) {
            return '';
          }
          const plain = sourceText
            .replace(/```[\s\S]*?```/g, ' ')
            .replace(/[#>*`\-]/g, ' ')
            .replace(/\s+/g, ' ')
            .trim();
          if (!plain) {
            return '';
          }
          return plain.length > 110 ? `${plain.slice(0, 110)}â€¦` : plain;
        };

        // è©³æƒ…é ï¼ˆæ»¿ç‰ˆï¼‰
        if (isResultDetailsOpen && currentJob) {
          return (
            <div className="result-details">
              {(() => {
                // æº–å‚™è³‡æ–™ï¼šå¾ Markdown è§£æå„å€æ®µï¼ˆæ¦‚è¦ã€æ±ºè­°ç­‰ï¼‰ï¼Œä¸¦æ•´åˆçµæ§‹åŒ–æ‘˜è¦
                const minutesMd = (currentJob.summary || currentJob.result?.summary?.minutesMd || '').trim();
                const parseSections = (md: string): Record<string, string[]> => {
                  const out: Record<string, string[]> = {};
                  if (!md) return out;
                  const lines = md.split(/\r?\n/);
                  let key: string | null = null;
                  for (const raw of lines) {
                    const line = raw.trim();
                    if (!line) continue;
                    const m = line.match(/^##\s+(.+)$/);
                    if (m) { key = m[1].trim(); out[key] = out[key] || []; continue; }
                    // åˆ—è¡¨æˆ–æ®µè½éƒ½ç•¶ä½œä¸€è¡Œ
                    if (line.startsWith('-') || line.startsWith('â€¢')) {
                      const normalized = line.replace(/^[-â€¢]\s*/, '').trim();
                      if (key) { (out[key] = out[key] || []).push(normalized); }
                      continue;
                    }
                    if (key) { (out[key] = out[key] || []).push(line); }
                  }
                  return out;
                };

                const sections = parseSections(minutesMd);
                // åŒç¾©æ¨™é¡Œå°æ‡‰ï¼Œé¿å…ä¸åŒ Prompt é€ æˆåˆ†æ®µè½å·®
                const pick = (names: string[]): string[] => {
                  for (const n of names) {
                    if (sections[n] && sections[n].length) return sections[n];
                  }
                  return [];
                };
                // æ‘˜è¦å…¨æ–‡ï¼šç›´æ¥ä»¥æ•´ä»½ minutesMd æ‰å¹³åŒ–çš„è¡Œç‚ºä¸»ï¼ˆé¿å…è³‡è¨Šé‡æµå¤±ï¼‰
                const overview = Object.values(sections).flat();
                const decisions = pick(['æ±ºè­°èˆ‡çµè«–', 'é‡è¦æ±ºè­°', 'æ±ºè­°']);
                const highlightsFromMd = pick(['ä¸»è¦é‡é»', 'é‡é»æ‘˜è¦', 'é‡é»']);

                const summaryObj = currentJob.result?.summary as any;
                // åš´æ ¼æ¨¡å¼ï¼šåªæ¥å—æ¨¡å‹æ˜ç¢ºæ¨™è¨˜çš„ [é«˜]/[ä¸­]/[ä½]ï¼ˆåŠå½¢æ–¹æ‹¬è™Ÿï¼‹ç©ºæ ¼ï¼‰ï¼Œå…¶é¤˜ä¸æ¨æ–·ã€‚
                const parsePriorityFromText = (text: string): { clean: string; priority?: 'high'|'medium'|'low' } => {
                  const m = text.match(/^\s*\[(é«˜|ä¸­|ä½)\]\s+(.+)$/);
                  if (!m) return { clean: text.trim() };
                  const lvl = m[1];
                  const clean = m[2].trim();
                  const priority = lvl === 'é«˜' ? 'high' : lvl === 'ä¸­' ? 'medium' : 'low';
                  return { clean, priority };
                };
                const highlightsData = (summaryObj?.highlights && summaryObj.highlights.length > 0)
                  ? (summaryObj.highlights as any[]).map((h: any, i: number) => {
                      if (typeof h === 'string') {
                        const p = parsePriorityFromText(h);
                        return { id: String(i + 1), content: p.clean, priority: p.priority } as any;
                      }
                      // åªæ¥å— 'high'|'medium'|'low'ï¼Œå…¶é¤˜ç•¶ä½œç„¡å„ªå…ˆç´š
                      const pr = ((): 'high'|'medium'|'low'|undefined => {
                        const val = (h.priority || '').toString().toLowerCase();
                        return val === 'high' ? 'high' : val === 'medium' ? 'medium' : val === 'low' ? 'low' : undefined;
                      })();
                      return { id: String(i + 1), content: h.text || '', priority: pr } as any;
                    })
                  : highlightsFromMd.map((t, i) => {
                      const p = parsePriorityFromText(t);
                      // åƒ…åœ¨æ¨¡å‹æ˜ç¢ºè¼¸å‡º [é«˜]/[ä¸­]/[ä½] æ™‚æ¨™è¨˜ï¼›æ²’æœ‰å°±ä¸æ¨™
                      return { id: String(i + 1), content: p.clean, priority: p.priority } as any;
                    });

                const decisionsData = decisions.map((t, i) => ({ id: String(i + 1), content: t }));

                const parseTodoFromText = (line: string) => {
                  // æ”¯æ´ï¼šäº‹é …ï¼šâ€¦ï½œè² è²¬äººï¼šâ€¦ï½œæœŸé™ï¼šMM/DDï½œç‹€æ…‹ï¼šé€²è¡Œä¸­
                  const parts = line.split(/\s*[ï½œ|]\s*/);
                  let task = line, owner: string|undefined, due: string|undefined, status: 'pending'|'in-progress'|'completed'|undefined;
                  for (const part of parts) {
                    if (/äº‹é …[:ï¼š]/.test(part)) task = part.replace(/äº‹é …[:ï¼š]/, '').trim();
                    if (/è² è²¬äºº[:ï¼š]/.test(part)) owner = part.replace(/è² è²¬äºº[:ï¼š]/, '').trim();
                    if (/(æœŸé™|åˆ°æœŸ|æ—¥æœŸ)[:ï¼š]/.test(part)) due = part.replace(/(æœŸé™|åˆ°æœŸ|æ—¥æœŸ)[:ï¼š]/, '').trim();
                    if (/ç‹€æ…‹[:ï¼š]/.test(part)) {
                      const s = part.replace(/ç‹€æ…‹[:ï¼š]/, '').trim();
                      if (/å®Œæˆ/.test(s)) status = 'completed'; else if (/é€²è¡Œ/.test(s)) status = 'in-progress'; else status = 'pending';
                    }
                  }
                  return { task: task.trim(), owner, due, status: status || 'pending' };
                };
                const todosData = (summaryObj?.todos && (summaryObj.todos as any[]).length > 0)
                  ? ((summaryObj.todos as any[]).map((t: any, i: number) => ({ id: String(i + 1), task: t.task || t.text || '', assignee: t.owner, dueDate: t.due || t.deadline, status: ((): any => { const s = (t.status || '').toString(); if (/å®Œæˆ/.test(s)) return 'completed'; if (/é€²è¡Œ/.test(s)) return 'in-progress'; return 'pending'; })() })))
                  : ((sections['å¾…è¾¦äº‹é …'] || []).map((line: string, i: number) => { const parsed = parseTodoFromText(line); return { id: String(i + 1), task: parsed.task, assignee: parsed.owner, dueDate: parsed.due, status: parsed.status as any }; }));

                const timelineData = ((currentJob.timelineItems && currentJob.timelineItems.length > 0)
                  ? currentJob.timelineItems
                  : (summaryObj?.timeline || [])
                ).map((t: any, i: number) => ({
                  id: String(i + 1),
                  time: t.timeRange || t.time || undefined,
                  title: t.item,
                  description: t.desc || ''
                }));

                // è‹¥ MD ä¸­æ²’æœ‰ overviewï¼Œé€€è€Œç”¨æ•´ä»½ minutesMd çš„å‰å¹¾æ®µ
                const overviewFallback = () => {
                  if (!minutesMd) return [] as string[];
                  const paras = minutesMd
                    .split(/\r?\n/)
                    .map(l => l.trim())
                    .filter(Boolean)
                    .filter(l => !/^#/.test(l))
                    .map(l => l.replace(/^[-â€¢]\s*/, ''));
                  return paras.slice(0, 6);
                };

                const isProcessing = currentJob.status !== 'done' && currentJob.status !== 'failed';
                
                const parseTsToSeconds = (ts?: string): number | null => {
                  if (!ts) return null;
                  const start = ts.split('-')[0];
                  const parts = start.split(':').map(Number);
                  if (parts.some(n => Number.isNaN(n))) return null;
                  return (parts.length === 3)
                    ? parts[0] * 3600 + parts[1] * 60 + parts[2]
                    : parts[0] * 60 + parts[1];
                };
                const handleJumpToTranscript = (item: { time?: string }) => {
                  const startSec = parseTsToSeconds(item.time);
                  setResultViewMode('transcript');
                  setTimeout(() => {
                    if (startSec == null || !currentJob.transcriptSegments || currentJob.transcriptSegments.length === 0) {
                      transcriptContainerRef.current?.scrollTo({ top: 0, behavior: 'smooth' });
                      return;
                    }
                    let idx = currentJob.transcriptSegments.findIndex(seg => {
                      const s = typeof seg.start === 'number' ? seg.start : (parseTsToSeconds(String(seg.start)) ?? 0);
                      return s >= (startSec as number);
                    });
                    if (idx < 0) idx = 0;
                    const targetEl = transcriptItemRefs.current[idx];
                    targetEl?.scrollIntoView({ behavior: 'smooth', block: 'start' });
                  }, 50);
                };

                const renderDetailBody = () => {
                  if (resultViewMode === 'transcript') {
                    if (!currentJob.transcript) {
                      return (
                        <div className="jobs-empty" style={{ border: 'none', background: 'transparent', padding: '2rem' }}>
                          <p className="empty-state__text">å°šæœªç”¢å‡ºé€å­—ç¨¿å…§å®¹</p>
                        </div>
                      );
                    }
                    if (currentJob.transcriptSegments && currentJob.transcriptSegments.length > 0) {
                      return (
                        <div>
                          <TranscriptToolbarKit
                            query={transcriptQuery}
                            onQueryChange={setTranscriptQuery}
                            speakers={[...new Set(currentJob.transcriptSegments.map(s => s.speaker).filter(Boolean) as string[])]}
                            speaker={transcriptSpeaker}
                            onSpeakerChange={setTranscriptSpeaker}
                            onCopy={() => {
                              const content = buildExportContent(currentJob);
                              window.electronAPI?.clipboard?.writeText?.(content);
                            }}
                            onDownload={() => {
                              const blob = new Blob([buildExportContent(currentJob)], { type: 'text/plain;charset=utf-8' });
                              const url = URL.createObjectURL(blob);
                              const a = document.createElement('a');
                              a.href = url;
                              a.download = `${currentJob.filename.replace(/\.[^/.]+$/, '')}-transcript.txt`;
                              document.body.appendChild(a);
                              a.click();
                              URL.revokeObjectURL(url);
                              a.remove();
                            }}
                          />
                          <div className="result-transcript-list" ref={transcriptContainerRef}>
                            {currentJob.transcriptSegments
                              .filter(seg => (transcriptSpeaker ? seg.speaker === transcriptSpeaker : true))
                              .filter(seg => (transcriptQuery ? (seg.text?.toLowerCase()?.includes(transcriptQuery.toLowerCase())) : true))
                              .map((segment, idx) => {
                                const startLabel = typeof segment.start === 'number' ? formatSecondsToTimestamp(segment.start) : (segment.start as string) ?? '--:--';
                                const endLabel = typeof segment.end === 'number' ? formatSecondsToTimestamp(segment.end) : (segment.end as string) ?? '--:--';
                                return (
                                  <div ref={(el) => { transcriptItemRefs.current[idx] = el; }} key={`${segment.start}-${segment.end}-${idx}`} className="transcript-item">
                                    <div>
                                      <div className="transcript-item__speaker">{segment.speaker}</div>
                                      <div className="transcript-item__time">{startLabel} - {endLabel}</div>
                                    </div>
                                    <div style={{ flex: 1 }}>{segment.text}</div>
                                  </div>
                                );
                              })}
                          </div>
                        </div>
                      );
                    }
                    return <div style={{ whiteSpace: 'pre-wrap', lineHeight: 1.8 }}>{currentJob.transcript}</div>;
                  }
                  // summary mode
                  return (
                    <>
                      <SummaryCardKit summary={overview.length ? overview : overviewFallback()} fullContent={overview.length ? overview : overviewFallback()} />
                      <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                        <HighlightsCardKit items={highlightsData} />
                        <DecisionsCardKit items={decisionsData} />
                        <TodosCardKit items={todosData} />
                      </div>
                      <TimelineCardKit items={timelineData} onJump={handleJumpToTranscript} />
                      <div className="flex justify-end mt-2">
                        <button className="btn btn--surface" onClick={async () => {
                          try {
                            const tl = await geminiClient.generateTimelineOutline(
                              (currentJob.transcriptSegments || []).map(s => ({ start: typeof s.start === 'number' ? s.start : 0, end: typeof s.end === 'number' ? s.end : undefined, text: s.text }))
                            );
                            const normalized = tl.map((t: any, i: number) => ({ id: String(i + 1), time: t.time, title: t.item, description: t.desc || '' }));
                            updateJob(currentJob.id, { timelineItems: normalized });
                          } catch (e) {
                            console.warn('é‡è·‘æ™‚é–“è»¸å¤±æ•—:', e);
                          }
                        }}>é‡è·‘æ™‚é–“è»¸</button>
                      </div>
                      <section className="rounded-2xl border border-[#E2E8F0] bg-white p-4 shadow-[0_18px_40px_-24px_rgba(15,23,42,0.18)]">
                        <div className="flex items-center justify-between">
                          <h4 className="text-[#0F172A] font-semibold">æ¨¡å‹åŸå§‹æ‘˜è¦ï¼ˆMarkdownï¼‰</h4>
                          <button className="btn btn--surface" onClick={() => setShowRawSummary(v => !v)}>{showRawSummary ? 'æ”¶åˆ' : 'æŸ¥çœ‹'}</button>
                        </div>
                        {showRawSummary && (
                          <pre style={{ marginTop: 8, whiteSpace: 'pre-wrap', fontFamily: 'ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, monospace', fontSize: 13, color: '#334155' }}>
                            {currentJob.summary || 'ï¼ˆç„¡ï¼‰'}
                          </pre>
                        )}
                      </section>
                    </>
                  );
                };

                return (
                  <>
                    <KitResultHeader
                      fileName={currentJob.filename}
                      completedTime={currentJob.createdAt}
                      currentMode={resultViewMode}
                      onModeChange={(m) => setResultViewMode(m)}
                      onBack={() => setIsResultDetailsOpen(false)}
                      files={completedJobs.map(j => ({ id: j.id, label: j.filename }))}
                      onSelectFile={(id) => {
                        const idx = completedJobs.findIndex(j => j.id === id);
                        if (idx >= 0) setCurrentJobIndex(idx);
                      }}
                      showProgress={isProcessing}
                      progressValue={currentJob.progress || 0}
                      estimatedTime={currentJob.progressMessage?.match(/é ä¼°å‰©é¤˜\s([^ï¼‰]+)/)?.[1] || '--:--'}
                    />

                    <ProgressBar progress={currentJob.progress || 0} isVisible={isProcessing} />

                    <div className="result-content">
                      <div className="result-body result-single">{renderDetailBody()}</div>
                    </div>
                  </>
                );
              })()}
            </div>
          );
        }

        // æ¸…å–®é 
        return (
          <div className="page-scroll page-scroll--flush">
            <div className="result-layout">
              <div className="result-toolbar">
                <div className="page-heading">
                  <h2 className="page-heading__title">æœƒè­°è½‰éŒ„çµæœ</h2>
                </div>
              </div>

              <div className="result-collection">
                {pagedJobs.map((job, index) => {
                  const isActive = index === safeIndex;
                  const snippet = getResultSnippet(job);
                  return (
                    <div
                      key={job.id}
                      className={`result-card ${isActive ? 'is-active' : ''}`}
                      role="button"
                      tabIndex={0}
                      onClick={() => {
                        setCurrentJobIndex(index);
                        setIsResultDetailsOpen(true);
                      }}
                      onKeyDown={(event) => {
                        if (event.key === 'Enter' || event.key === ' ') {
                          event.preventDefault();
                          setCurrentJobIndex(index);
                          setIsResultDetailsOpen(true);
                        }
                      }}
                    >
                      <div className="result-card__header">
                        <div className="result-card__title" title={job.filename}>{require('./utils/filename').getDisplayName(job.filename, 'medium')}</div>
                        <button
                          type="button"
                          className="result-card__delete"
                          onClick={(event) => {
                            event.stopPropagation();
                            handleDeleteJob(job.id);
                          }}
                          title="åˆªé™¤è½‰éŒ„çµæœ"
                        >
                          åˆªé™¤
                        </button>
                      </div>
                      <div className="result-card__meta">å®Œæˆæ™‚é–“ï¼š{job.createdAt}</div>
                      {/* çµ±ä¸€ä¸é¡¯ç¤ºæœ¬æ©Ÿæª”æ¡ˆè·¯å¾‘ï¼Œé¿å…æ´©éœ²/éé•·å¹²æ“¾ç‰ˆé¢ */}
                      {snippet && (
                        <p className="result-card__snippet">{snippet}</p>
                      )}
                      <div className="result-card__footer">
                        <span className="chip chip--success">å·²å®Œæˆ</span>
                        <button
                          type="button"
                          className="result-card__view"
                          onClick={(event) => {
                            event.stopPropagation();
                            setCurrentJobIndex(index);
                            setIsResultDetailsOpen(true);
                          }}
                        >
                          æŸ¥çœ‹
                        </button>
                      </div>
                    </div>
                  );
                })}
              </div>
              {totalPages > 1 && (
                <div style={{ display: 'flex', justifyContent: 'center', alignItems: 'center', gap: 8, marginTop: 16 }}>
                  <button
                    type="button"
                    className="btn btn--surface"
                    disabled={currentPage <= 1}
                    onClick={() => setResultsPage(p => Math.max(1, p - 1))}
                  >ä¸Šä¸€é </button>
                  {Array.from({ length: totalPages }, (_, i) => i + 1).map(p => (
                    <button
                      key={p}
                      type="button"
                      className="btn btn--minimal"
                      style={{
                        background: p === currentPage ? 'rgba(226,232,240,0.9)' : undefined,
                        border: '1px solid rgba(226,232,240,0.8)'
                      }}
                      onClick={() => setResultsPage(p)}
                    >{p}</button>
                  ))}
                  <button
                    type="button"
                    className="btn btn--surface"
                    disabled={currentPage >= totalPages}
                    onClick={() => setResultsPage(p => Math.min(totalPages, p + 1))}
                  >ä¸‹ä¸€é </button>
                </div>
              )}
            </div>
          </div>
        );
      }
      case 'settings':
        return (
          <div style={{ width: '100%', maxWidth: '960px', margin: '0 auto', textAlign: 'left' }}><SettingsPage /></div>
        );
      case 'stt':
        return (
          <div style={{ width: '100%', maxWidth: '960px', margin: '0 auto', textAlign: 'left' }}><GoogleSTTSettingsPage /></div>
        );
      case 'prompts':
        return <PromptsPage />;
      default:
        return <div>Unknown page</div>;
    }
  };

  const activeJobCountValue = jobs.filter(job => job.status !== 'done' && job.status !== 'failed').length;
  const completedJobCountValue = jobs.filter(job => job.status === 'done').length;
  const pageMeta = PAGE_META[currentPage];
  const isRecordPage = currentPage === 'record';
  const useFluidContent =
    currentPage === 'record' ||
    currentPage === 'prompts' ||
    currentPage === 'settings' ||
    (currentPage === 'result' && isResultDetailsOpen);

  return (
    <div className="app-shell">
      <SimpleNavigation
        currentPage={currentPage === 'stt' ? 'settings' : currentPage}
        onPageChange={setCurrentPage as any}
        jobCount={jobs.length}
        activeJobCount={activeJobCountValue}
        completedJobCount={completedJobCountValue}
        settings={settings}
        appVersion={appVersion}
        updateStatus={updateStatusMessage}
        updateAvailable={updateAvailable}
        updateDownloaded={updateDownloaded}
        updateProgress={updateProgress}
        updateInfo={updateInfo}
        onCheckUpdates={handleCheckUpdates}
        onDownloadUpdate={handleDownloadUpdate}
        onInstallUpdate={handleInstallUpdate}
      />

      <div className={`app-main${isRecordPage ? ' app-main--record' : ''}`}>
        {!isRecordPage && !(currentPage === 'result' && isResultDetailsOpen) && (
          <header className="app-main__header">
            <div className="page-heading">
              <h1 className="page-heading__title">{pageMeta.title}</h1>
              <p className="page-heading__subtitle">{pageMeta.subtitle}</p>
            </div>
          </header>
        )}

        <div className={`app-main__content${useFluidContent ? ' app-main__content--fluid' : ''}${currentPage === 'settings' ? ' app-main__content--settings' : ''}`}>
          {renderCurrentPage()}
        </div>
      </div>
    </div>
  );
};

export default App;
