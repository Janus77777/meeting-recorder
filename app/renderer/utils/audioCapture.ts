export type CaptureSource = 'display' | 'virtual-device' | 'loopback' | 'none';

export interface SystemAudioCaptureResult {
  stream: MediaStream | null;
  source: CaptureSource;
  warnings: string[];
  error?: string;
}

export interface SystemAudioCaptureOptions {
  platform?: NodeJS.Platform | 'unknown';
  /**
   * When true, try display capture first. macOS requires this to grab system audio.
   */
  preferDisplayCapture?: boolean;
  /**
   * Provide a way to log diagnostic messages without coupling to UI.
   */
  logger?: (message: string, data?: unknown) => void;
}

export interface MicrophoneCaptureOptions {
  deviceId?: string;
  echoCancellation?: boolean;
  noiseSuppression?: boolean;
  autoGainControl?: boolean;
  sampleRate?: number;
  logger?: (message: string, data?: unknown) => void;
}

const SYSTEM_AUDIO_KEYWORDS = [
  'stereo mix',
  'ç«‹é«”è²æ··éŸ³',
  'what u hear',
  'loopback',
  'cable',
  'voicemeeter',
  'virtual',
  'system'
];

const log = (logger?: (message: string, data?: unknown) => void, message?: string, data?: unknown) => {
  if (logger && message) {
    logger(message, data);
  } else if (message) {
    console.log(message, data ?? '');
  }
};

export const requestMicrophoneStream = async (
  options: MicrophoneCaptureOptions = {}
): Promise<MediaStream> => {
  if (!navigator.mediaDevices?.getUserMedia) {
    throw new Error('ç€è¦½å™¨ä¸æ”¯æ´éŸ³è¨Šæ“·å–');
  }

  const {
    deviceId,
    echoCancellation = true,
    noiseSuppression = true,
    autoGainControl = true,
    sampleRate = 44100
  } = options;

  log(options.logger, 'ğŸ™ï¸ æ­£åœ¨è«‹æ±‚éº¥å…‹é¢¨ä¸²æµ');

  return navigator.mediaDevices.getUserMedia({
    audio: {
      deviceId,
      echoCancellation,
      noiseSuppression,
      autoGainControl,
      sampleRate
    },
    video: false
  });
};

export const requestSystemAudioStream = async (
  options: SystemAudioCaptureOptions = {}
): Promise<SystemAudioCaptureResult> => {
  const platform = options.platform ?? 'unknown';
  const preferDisplayCapture = options.preferDisplayCapture ?? platform === 'darwin';
  const warnings: string[] = [];

  // Try display capture (works on macOS and modern Windows builds)
  if (preferDisplayCapture && navigator.mediaDevices?.getDisplayMedia) {
    try {
      log(options.logger, 'ğŸ–¥ï¸ å˜—è©¦é€éè¢å¹•éŒ„è£½å–å¾—ç³»çµ±è²éŸ³');
      const displayConstraints: DisplayMediaStreamOptions = {
        audio: true,
        video: {
          width: 1,
          height: 1,
          frameRate: 1
        }
      };

      // On Windows we prefer audio only, but some platforms require video flag
      if (platform !== 'darwin') {
        displayConstraints.video = false;
      }

      const displayStream = await navigator.mediaDevices.getDisplayMedia(displayConstraints);
      const audioTracks = displayStream.getAudioTracks();

      if (audioTracks.length > 0) {
        log(options.logger, 'âœ… å·²å–å¾—è¢å¹•éŸ³è¨Šè»Œé“', audioTracks.map(track => ({
          id: track.id,
          label: track.label,
          kind: track.kind
        })));

        // Stop all video tracks immediately â€“ we only care about audio
        displayStream.getVideoTracks().forEach(track => track.stop());

        const audioStream = new MediaStream();
        audioTracks.forEach(track => audioStream.addTrack(track));

        return {
          stream: audioStream,
          source: 'display',
          warnings
        };
      }

      warnings.push('è¢å¹•éŒ„è£½æœªæä¾›ä»»ä½•éŸ³è¨Šè»Œé“');
      displayStream.getTracks().forEach(track => track.stop());
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      warnings.push(`è¢å¹•éŒ„è£½å¤±æ•—ï¼š${message}`);
      log(options.logger, 'âŒ è¢å¹•éŒ„è£½å–å¾—ç³»çµ±è²éŸ³å¤±æ•—', error);
    }
  }

  // Fallback: look for virtual/loopback audio input devices (primarily Windows)
  if (navigator.mediaDevices?.enumerateDevices) {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');

      const virtualDevice = audioInputs.find(device => {
        const label = device.label.toLowerCase();
        return SYSTEM_AUDIO_KEYWORDS.some(keyword => label.includes(keyword));
      });

      if (virtualDevice) {
        log(options.logger, 'ğŸ§ ä½¿ç”¨è™›æ“¬éŸ³è¨Šè¨­å‚™æ“·å–ç³»çµ±è²éŸ³', virtualDevice.label);
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            deviceId: { exact: virtualDevice.deviceId },
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          },
          video: false
        });

        return {
          stream,
          source: 'virtual-device',
          warnings
        };
      }

      warnings.push('æœªåµæ¸¬åˆ°è™›æ“¬éŸ³è¨Šæˆ–ç«‹é«”è²æ··éŸ³è¨­å‚™');
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      warnings.push(`åµæ¸¬éŸ³è¨Šè¨­å‚™å¤±æ•—ï¼š${message}`);
      log(options.logger, 'âŒ åµæ¸¬éŸ³è¨Šè¨­å‚™å¤±æ•—', error);
    }
  } else {
    warnings.push('ç•¶å‰ç’°å¢ƒä¸æ”¯æ´è£ç½®åµæ¸¬');
  }

  return {
    stream: null,
    source: 'none',
    warnings,
    error: warnings[warnings.length - 1]
  };
};

export const mergeMediaStreams = (streams: MediaStream[]): MediaStream => {
  const audioContext = new AudioContext();
  const destination = audioContext.createMediaStreamDestination();

  streams.forEach(stream => {
    if (stream.getAudioTracks().length > 0) {
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(destination);
    }
  });

  return destination.stream;
};

export const stopStream = (stream: MediaStream | null | undefined): void => {
  if (!stream) {
    return;
  }

  stream.getTracks().forEach(track => {
    track.stop();
  });
};
